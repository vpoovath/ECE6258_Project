Imports successful
Model Init Done.
Preprocessing Step Successful.
Initialization of train_data and val_data successful.
Training loop started:
[Epoch 0] train=0.176743 val=0.267800 loss=136119.622650 time: 148.284893
[Epoch 1] train=0.306010 val=0.334000 loss=111156.473312 time: 147.379815
[Epoch 2] train=0.382752 val=0.413500 loss=97996.595596 time: 147.105559
[Epoch 3] train=0.438341 val=0.434200 loss=88535.578506 time: 146.959326
[Epoch 4] train=0.483954 val=0.492200 loss=81437.846497 time: 149.606736
[Epoch 5] train=0.519471 val=0.510900 loss=75480.532410 time: 148.963479
[Epoch 6] train=0.545513 val=0.507800 loss=71087.371750 time: 149.453788
[Epoch 7] train=0.571354 val=0.517600 loss=67192.611603 time: 146.527477
[Epoch 8] train=0.589143 val=0.572800 loss=63981.068001 time: 149.110653
[Epoch 9] train=0.607292 val=0.593500 loss=61211.812012 time: 147.576253
[Epoch 10] train=0.619431 val=0.578500 loss=59030.642776 time: 147.760244
[Epoch 11] train=0.635216 val=0.603100 loss=56688.404167 time: 150.399113
[Epoch 12] train=0.646935 val=0.627400 loss=54795.430031 time: 148.500349
[Epoch 13] train=0.658774 val=0.630100 loss=52882.532745 time: 146.184797
[Epoch 14] train=0.670072 val=0.627500 loss=51340.171082 time: 148.175374
[Epoch 15] train=0.678325 val=0.648600 loss=49717.225296 time: 148.812896
[Epoch 16] train=0.687099 val=0.646000 loss=48440.973175 time: 147.785265
[Epoch 17] train=0.693289 val=0.652800 loss=47140.417877 time: 147.304158
[Epoch 18] train=0.701142 val=0.667200 loss=46229.072746 time: 149.099938
[Epoch 19] train=0.711298 val=0.654000 loss=44373.493309 time: 145.578210
[Epoch 20] train=0.720373 val=0.661000 loss=43571.144119 time: 148.961776
[Epoch 21] train=0.723798 val=0.661200 loss=42487.405540 time: 147.865596
[Epoch 22] train=0.731490 val=0.673200 loss=41334.630119 time: 147.215417
[Epoch 23] train=0.736138 val=0.673800 loss=40368.327713 time: 146.649426
[Epoch 24] train=0.741186 val=0.681400 loss=39630.320816 time: 149.121571
[Epoch 25] train=0.748197 val=0.679900 loss=38815.033211 time: 148.626159
[Epoch 26] train=0.752905 val=0.674900 loss=37772.132969 time: 147.924170
[Epoch 27] train=0.757492 val=0.688000 loss=37064.450657 time: 147.062844
[Epoch 28] train=0.761318 val=0.689700 loss=36412.872799 time: 150.209098
[Epoch 29] train=0.769812 val=0.681200 loss=35250.866486 time: 148.858845
[Epoch 30] train=0.810857 val=0.730100 loss=28960.784920 time: 148.076873
[Epoch 31] train=0.825160 val=0.732600 loss=26842.411911 time: 149.513863
[Epoch 32] train=0.827644 val=0.734900 loss=26287.552185 time: 145.157746
[Epoch 33] train=0.834315 val=0.735100 loss=25537.484047 time: 148.456787
[Epoch 34] train=0.836398 val=0.735400 loss=24927.049522 time: 147.129761
[Epoch 35] train=0.839824 val=0.734900 loss=24572.054039 time: 146.519216
[Epoch 36] train=0.839884 val=0.734700 loss=24295.988155 time: 147.931031
[Epoch 37] train=0.845493 val=0.735000 loss=23839.270374 time: 146.986105
[Epoch 38] train=0.847396 val=0.736400 loss=23421.862698 time: 146.662049
[Epoch 39] train=0.846354 val=0.735700 loss=23324.626858 time: 148.194717
[Epoch 40] train=0.850781 val=0.737800 loss=22968.497372 time: 146.458595
[Epoch 41] train=0.851402 val=0.736800 loss=22514.668722 time: 146.046046
[Epoch 42] train=0.851723 val=0.734500 loss=22580.216673 time: 147.628356
[Epoch 43] train=0.852123 val=0.735800 loss=22359.170769 time: 147.599807
[Epoch 44] train=0.857372 val=0.735000 loss=21829.198874 time: 146.197806
[Epoch 45] train=0.855489 val=0.735900 loss=21738.715208 time: 147.247132
[Epoch 46] train=0.857232 val=0.733500 loss=21707.559309 time: 149.607046
[Epoch 47] train=0.860697 val=0.739700 loss=21365.109035 time: 148.594351
[Epoch 48] train=0.859455 val=0.734300 loss=21258.138660 time: 149.839677
[Epoch 49] train=0.862079 val=0.734900 loss=20939.709597 time: 147.698120
[Epoch 50] train=0.863341 val=0.734100 loss=20725.275175 time: 147.349709
[Epoch 51] train=0.864764 val=0.734300 loss=20388.702854 time: 148.396870
[Epoch 52] train=0.867167 val=0.734100 loss=20287.307304 time: 148.825039
[Epoch 53] train=0.865084 val=0.730700 loss=20224.285255 time: 149.818073
[Epoch 54] train=0.868309 val=0.733400 loss=20109.416496 time: 147.638018
[Epoch 55] train=0.866947 val=0.733600 loss=19973.846516 time: 148.310628
[Epoch 56] train=0.871735 val=0.733200 loss=19469.486021 time: 146.457314
[Epoch 57] train=0.870713 val=0.736000 loss=19513.527658 time: 147.959626
[Epoch 58] train=0.872616 val=0.734200 loss=19408.148544 time: 152.718680
[Epoch 59] train=0.872977 val=0.736700 loss=19183.415867 time: 149.444392
[Epoch 60] train=0.879948 val=0.738100 loss=18366.027143 time: 146.989677
[Epoch 61] train=0.878746 val=0.738100 loss=18442.071798 time: 148.713405
[Epoch 62] train=0.881811 val=0.737200 loss=18041.271091 time: 147.404911
[Epoch 63] train=0.880188 val=0.737800 loss=18172.831968 time: 146.073095
[Epoch 64] train=0.880148 val=0.738100 loss=18033.433651 time: 148.148014
[Epoch 65] train=0.881510 val=0.738000 loss=17954.530226 time: 146.339866
[Epoch 66] train=0.882252 val=0.737800 loss=17862.473145 time: 150.040369
[Epoch 67] train=0.882973 val=0.736300 loss=17710.112448 time: 148.289395
[Epoch 68] train=0.883774 val=0.736200 loss=17802.204287 time: 150.048047
[Epoch 69] train=0.882772 val=0.737400 loss=17782.993010 time: 149.662691
[Epoch 70] train=0.884034 val=0.736300 loss=17715.199661 time: 149.452025
[Epoch 71] train=0.886038 val=0.735900 loss=17651.464874 time: 146.817439
[Epoch 72] train=0.882672 val=0.738700 loss=17676.488874 time: 146.317514
[Epoch 73] train=0.883173 val=0.737200 loss=17568.069067 time: 147.732921
[Epoch 74] train=0.883093 val=0.737500 loss=17733.161013 time: 148.971593
[Epoch 75] train=0.884435 val=0.735300 loss=17591.804010 time: 147.324403
[Epoch 76] train=0.884315 val=0.738200 loss=17479.124184 time: 151.161853
[Epoch 77] train=0.885136 val=0.737800 loss=17454.746820 time: 149.762183
[Epoch 78] train=0.883494 val=0.737500 loss=17601.819983 time: 149.400093
[Epoch 79] train=0.885216 val=0.736500 loss=17476.160545 time: 147.134859
[Epoch 80] train=0.886819 val=0.737400 loss=17264.241728 time: 146.233124
[Epoch 81] train=0.884996 val=0.737000 loss=17429.047180 time: 148.665509
[Epoch 82] train=0.883113 val=0.737500 loss=17538.545509 time: 151.302453
[Epoch 83] train=0.885557 val=0.735300 loss=17345.221109 time: 148.324546
[Epoch 84] train=0.882612 val=0.738000 loss=17530.024693 time: 148.886796
[Epoch 85] train=0.884054 val=0.735800 loss=17463.111864 time: 149.577545
[Epoch 86] train=0.885116 val=0.736800 loss=17415.788422 time: 147.959149
[Epoch 87] train=0.885897 val=0.737900 loss=17329.124043 time: 146.799771
[Epoch 88] train=0.887200 val=0.737100 loss=17235.779602 time: 148.640357
[Epoch 89] train=0.886999 val=0.736800 loss=17214.742733 time: 146.514167
[Epoch 90] train=0.886759 val=0.738800 loss=17198.565725 time: 147.923119
[Epoch 91] train=0.887220 val=0.736700 loss=17193.589165 time: 147.500324
[Epoch 92] train=0.889083 val=0.736100 loss=17007.198193 time: 148.698635
[Epoch 93] train=0.885597 val=0.737400 loss=17133.178514 time: 148.587886
[Epoch 94] train=0.889163 val=0.735500 loss=16973.900833 time: 149.970423
[Epoch 95] train=0.889042 val=0.737400 loss=17042.389803 time: 148.470586
[Epoch 96] train=0.888421 val=0.736700 loss=17090.361105 time: 145.496655
[Epoch 97] train=0.886759 val=0.737500 loss=17185.650324 time: 146.932140
[Epoch 98] train=0.886719 val=0.735400 loss=17174.523293 time: 149.315185
[Epoch 99] train=0.888181 val=0.736800 loss=17053.804754 time: 147.780650
[Epoch 100] train=0.885136 val=0.736000 loss=17099.397411 time: 147.031687
[Epoch 101] train=0.887720 val=0.736400 loss=17115.144987 time: 147.821933
[Epoch 102] train=0.887340 val=0.736400 loss=17078.484566 time: 145.693717
[Epoch 103] train=0.887760 val=0.736600 loss=16977.528681 time: 147.333241
[Epoch 104] train=0.885978 val=0.737100 loss=17186.806129 time: 147.059461
[Epoch 105] train=0.889002 val=0.737800 loss=17096.221506 time: 149.156824
[Epoch 106] train=0.886979 val=0.738100 loss=17126.751886 time: 147.982416
[Epoch 107] train=0.889623 val=0.736200 loss=16948.129391 time: 148.221157
[Epoch 108] train=0.887380 val=0.739700 loss=17001.031538 time: 147.361747
[Epoch 109] train=0.887420 val=0.736700 loss=17071.696447 time: 149.762263
[Epoch 110] train=0.886498 val=0.737100 loss=16996.898521 time: 148.039214
[Epoch 111] train=0.886478 val=0.737100 loss=17129.296680 time: 150.156025
[Epoch 112] train=0.887620 val=0.737100 loss=17044.239849 time: 148.324790
[Epoch 113] train=0.885697 val=0.739000 loss=17233.505819 time: 146.581368
[Epoch 114] train=0.886639 val=0.737600 loss=17113.190786 time: 152.106802
[Epoch 115] train=0.886739 val=0.736500 loss=17101.377903 time: 148.789004
[Epoch 116] train=0.884515 val=0.737200 loss=17405.893723 time: 148.168594
[Epoch 117] train=0.887360 val=0.737300 loss=17082.562860 time: 147.413841
[Epoch 118] train=0.887420 val=0.737100 loss=17063.317736 time: 148.253598
[Epoch 119] train=0.886458 val=0.737000 loss=17171.520695 time: 147.295326
Done.
