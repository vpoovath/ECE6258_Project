Imports successful
Model Init Done.
Preprocessing Step Successful.
Initialization of train_data and val_data successful.
Training loop started:
[Epoch 0] train=0.174599 val=0.208600 loss=136843.438324 time: 149.715549
[Epoch 1] train=0.303886 val=0.261400 loss=111450.051651 time: 150.738848
[Epoch 2] train=0.382552 val=0.348700 loss=97757.444717 time: 148.459851
[Epoch 3] train=0.441987 val=0.433700 loss=88136.576004 time: 152.046106
[Epoch 4] train=0.487540 val=0.485400 loss=81060.368332 time: 151.293975
[Epoch 5] train=0.517288 val=0.444900 loss=75693.189804 time: 152.970413
[Epoch 6] train=0.548538 val=0.526100 loss=71006.115219 time: 152.700476
[Epoch 7] train=0.568970 val=0.555100 loss=67255.125687 time: 153.122664
[Epoch 8] train=0.588421 val=0.562600 loss=63894.005730 time: 151.490880
[Epoch 9] train=0.605809 val=0.574100 loss=61477.503372 time: 153.738104
[Epoch 10] train=0.619812 val=0.595900 loss=59039.914871 time: 150.576016
[Epoch 11] train=0.635016 val=0.604400 loss=56810.244217 time: 148.737190
[Epoch 12] train=0.647556 val=0.615300 loss=54685.720665 time: 152.924481
[Epoch 13] train=0.660056 val=0.622200 loss=52725.769012 time: 148.576064
[Epoch 14] train=0.666226 val=0.620400 loss=51473.640877 time: 150.927081
[Epoch 15] train=0.676162 val=0.655600 loss=49827.818939 time: 151.510923
[Epoch 16] train=0.685296 val=0.651700 loss=48331.612015 time: 147.872711
[Epoch 17] train=0.694611 val=0.643300 loss=46950.704597 time: 153.218746
[Epoch 18] train=0.704267 val=0.650300 loss=45591.418762 time: 153.315588
[Epoch 19] train=0.713622 val=0.656300 loss=44180.982323 time: 148.914337
[Epoch 20] train=0.716206 val=0.656600 loss=43561.282639 time: 152.067849
[Epoch 21] train=0.723478 val=0.668900 loss=42202.341385 time: 149.559721
[Epoch 22] train=0.730990 val=0.651400 loss=41359.655807 time: 148.813189
[Epoch 23] train=0.737600 val=0.682000 loss=40241.203415 time: 148.827423
[Epoch 24] train=0.741687 val=0.683300 loss=39403.236603 time: 149.172338
[Epoch 25] train=0.749800 val=0.663200 loss=38421.630737 time: 153.217308
[Epoch 26] train=0.756310 val=0.671300 loss=37487.699478 time: 153.693245
[Epoch 27] train=0.760156 val=0.694600 loss=36587.236557 time: 151.638806
[Epoch 28] train=0.763442 val=0.698100 loss=36059.593086 time: 149.988580
[Epoch 29] train=0.771575 val=0.696800 loss=34886.590012 time: 150.620615
[Epoch 30] train=0.772436 val=0.698700 loss=34660.638184 time: 153.549402
[Epoch 31] train=0.779808 val=0.702900 loss=33799.276936 time: 151.241671
[Epoch 32] train=0.782372 val=0.701900 loss=33045.747223 time: 148.370404
[Epoch 33] train=0.788762 val=0.698800 loss=32190.903412 time: 148.453647
[Epoch 34] train=0.793450 val=0.704300 loss=31496.255051 time: 148.825847
[Epoch 35] train=0.795413 val=0.682500 loss=30953.980740 time: 152.988829
[Epoch 36] train=0.798357 val=0.699300 loss=30554.104424 time: 151.047112
[Epoch 37] train=0.803906 val=0.692400 loss=29567.347172 time: 152.287084
[Epoch 38] train=0.804247 val=0.699000 loss=29347.931789 time: 146.946728
[Epoch 39] train=0.810296 val=0.695200 loss=28786.285702 time: 150.333042
[Epoch 40] train=0.816406 val=0.697700 loss=27937.341225 time: 148.001337
[Epoch 41] train=0.816907 val=0.704700 loss=27785.078667 time: 150.085128
[Epoch 42] train=0.822236 val=0.702400 loss=27092.864231 time: 149.282553
[Epoch 43] train=0.822416 val=0.702800 loss=26652.941559 time: 153.482394
[Epoch 44] train=0.826743 val=0.713900 loss=26100.391087 time: 148.578730
[Epoch 45] train=0.828446 val=0.706700 loss=25834.472923 time: 153.873750
[Epoch 46] train=0.834395 val=0.712000 loss=25040.874283 time: 151.502191
[Epoch 47] train=0.836218 val=0.711700 loss=24770.543133 time: 149.767696
[Epoch 48] train=0.837841 val=0.719300 loss=24216.796021 time: 148.384588
[Epoch 49] train=0.838642 val=0.713300 loss=24015.858555 time: 153.316288
[Epoch 50] train=0.843970 val=0.717000 loss=23206.586557 time: 149.649935
[Epoch 51] train=0.847576 val=0.703800 loss=22954.830532 time: 150.525238
[Epoch 52] train=0.848858 val=0.713500 loss=22807.689371 time: 151.768579
[Epoch 53] train=0.851222 val=0.720000 loss=22264.892509 time: 150.609370
[Epoch 54] train=0.856110 val=0.702700 loss=21665.317352 time: 151.062459
[Epoch 55] train=0.854587 val=0.713700 loss=21610.309696 time: 152.690045
[Epoch 56] train=0.858614 val=0.716400 loss=20897.170242 time: 150.654891
[Epoch 57] train=0.861158 val=0.712300 loss=20753.102995 time: 149.197244
[Epoch 58] train=0.862440 val=0.715100 loss=20530.432383 time: 149.895048
[Epoch 59] train=0.867067 val=0.720500 loss=19808.173021 time: 152.881911
[Epoch 60] train=0.864764 val=0.720900 loss=20098.519384 time: 150.807517
[Epoch 61] train=0.869411 val=0.720300 loss=19316.640251 time: 149.976445
[Epoch 62] train=0.873317 val=0.720900 loss=19058.042048 time: 152.177980
[Epoch 63] train=0.872596 val=0.720500 loss=19041.612446 time: 153.274385
[Epoch 64] train=0.875240 val=0.715800 loss=18530.912783 time: 150.475407
[Epoch 65] train=0.874619 val=0.719400 loss=18605.091013 time: 151.615109
[Epoch 66] train=0.877304 val=0.713400 loss=18325.395380 time: 151.775661
[Epoch 67] train=0.880929 val=0.724700 loss=17623.857252 time: 150.184121
[Epoch 68] train=0.881370 val=0.718600 loss=17646.882673 time: 148.934571
[Epoch 69] train=0.883754 val=0.712300 loss=17231.090776 time: 150.426564
[Epoch 70] train=0.885637 val=0.729600 loss=16953.184645 time: 149.928323
[Epoch 71] train=0.886799 val=0.720900 loss=16927.208864 time: 152.062652
[Epoch 72] train=0.889203 val=0.720300 loss=16545.623699 time: 149.426722
[Epoch 73] train=0.889744 val=0.732400 loss=16237.533783 time: 153.095373
[Epoch 74] train=0.891587 val=0.727400 loss=16115.714474 time: 151.162506
[Epoch 75] train=0.894692 val=0.718600 loss=15658.793453 time: 148.602752
[Epoch 76] train=0.893850 val=0.717200 loss=15659.694613 time: 149.618332
[Epoch 77] train=0.894671 val=0.723300 loss=15672.907585 time: 151.496799
[Epoch 78] train=0.897877 val=0.722000 loss=15161.749050 time: 152.202420
[Epoch 79] train=0.899760 val=0.721200 loss=14894.551685 time: 150.075359
[Epoch 80] train=0.896615 val=0.726600 loss=15278.987980 time: 147.516966
[Epoch 81] train=0.900441 val=0.722600 loss=14743.957954 time: 147.566064
[Epoch 82] train=0.901182 val=0.730500 loss=14508.347170 time: 150.797981
[Epoch 83] train=0.904067 val=0.724100 loss=14095.592552 time: 151.840473
[Epoch 84] train=0.905168 val=0.721400 loss=13990.505951 time: 151.486457
[Epoch 85] train=0.905929 val=0.722900 loss=13867.253963 time: 148.628697
[Epoch 86] train=0.907051 val=0.724400 loss=13668.558135 time: 151.002413
[Epoch 87] train=0.906250 val=0.724100 loss=13682.425860 time: 153.756539
[Epoch 88] train=0.911278 val=0.718100 loss=13186.824087 time: 150.452814
[Epoch 89] train=0.909635 val=0.727400 loss=13185.998821 time: 151.923532
[Epoch 90] train=0.910317 val=0.726900 loss=13166.737730 time: 148.012741
[Epoch 91] train=0.910076 val=0.720900 loss=13235.656484 time: 153.947596
[Epoch 92] train=0.912420 val=0.724200 loss=13007.201418 time: 153.267466
[Epoch 93] train=0.913482 val=0.724500 loss=12631.312983 time: 152.091177
[Epoch 94] train=0.916346 val=0.728000 loss=12299.713273 time: 148.042256
[Epoch 95] train=0.913502 val=0.715800 loss=12681.761913 time: 152.974217
[Epoch 96] train=0.915665 val=0.728400 loss=12264.909810 time: 151.123980
[Epoch 97] train=0.915244 val=0.732600 loss=12297.477258 time: 151.947497
[Epoch 98] train=0.919411 val=0.729400 loss=11865.554639 time: 147.508720
[Epoch 99] train=0.919071 val=0.724900 loss=11851.449643 time: 150.156806
[Epoch 100] train=0.917228 val=0.735500 loss=12057.472658 time: 149.643603
