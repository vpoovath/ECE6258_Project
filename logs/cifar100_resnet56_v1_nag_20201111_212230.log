Imports successful
Model Init Done.
Preprocessing Step Successful.
Initialization of train_data and val_data successful.
Training loop started:
[Epoch 0] train=0.109836 val_top1=0.202200 val_top5=0.552800 loss=146903.720642 time: 32.246735
[Epoch 1] train=0.228686 val_top1=0.289400 val_top5=0.696200 loss=124063.085327 time: 31.992001
[Epoch 2] train=0.321955 val_top1=0.339300 val_top5=0.734200 loss=108041.801315 time: 32.126484
[Epoch 3] train=0.391506 val_top1=0.391400 val_top5=0.779800 loss=96266.851120 time: 31.927515
[Epoch 4] train=0.442328 val_top1=0.459400 val_top5=0.850700 loss=87701.236664 time: 31.871733
[Epoch 5] train=0.483694 val_top1=0.493200 val_top5=0.858200 loss=81301.857803 time: 31.987047
[Epoch 6] train=0.514383 val_top1=0.518300 val_top5=0.872500 loss=76056.817734 time: 32.103671
[Epoch 7] train=0.542748 val_top1=0.539200 val_top5=0.877600 loss=71571.580765 time: 32.246603
[Epoch 8] train=0.563321 val_top1=0.547200 val_top5=0.877500 loss=68134.510925 time: 31.991892
[Epoch 9] train=0.585196 val_top1=0.554400 val_top5=0.874200 loss=65339.725464 time: 32.023285
[Epoch 10] train=0.598838 val_top1=0.594000 val_top5=0.906900 loss=62519.973473 time: 31.946570
[Epoch 11] train=0.612079 val_top1=0.606100 val_top5=0.910800 loss=60709.446983 time: 31.847106
[Epoch 12] train=0.625361 val_top1=0.598300 val_top5=0.897800 loss=58302.424416 time: 32.024581
[Epoch 13] train=0.639062 val_top1=0.611500 val_top5=0.908500 loss=56569.422562 time: 32.132382
[Epoch 14] train=0.646995 val_top1=0.618200 val_top5=0.907600 loss=54744.751953 time: 32.148889
[Epoch 15] train=0.659495 val_top1=0.609300 val_top5=0.917900 loss=53068.133774 time: 31.996641
[Epoch 16] train=0.667027 val_top1=0.585100 val_top5=0.899700 loss=51806.694649 time: 31.983446
[Epoch 17] train=0.672897 val_top1=0.634500 val_top5=0.921600 loss=50665.903191 time: 31.819246
[Epoch 18] train=0.681911 val_top1=0.630300 val_top5=0.912200 loss=49262.329033 time: 32.169271
[Epoch 19] train=0.688341 val_top1=0.639800 val_top5=0.921300 loss=48485.037888 time: 32.017131
[Epoch 20] train=0.694291 val_top1=0.636000 val_top5=0.928100 loss=47428.519081 time: 32.184600
[Epoch 21] train=0.701042 val_top1=0.664700 val_top5=0.938100 loss=46085.243805 time: 32.063719
[Epoch 22] train=0.704207 val_top1=0.650300 val_top5=0.923200 loss=45505.654083 time: 32.013992
[Epoch 23] train=0.713622 val_top1=0.640900 val_top5=0.915400 loss=44547.051987 time: 31.821066
[Epoch 24] train=0.715765 val_top1=0.637700 val_top5=0.919700 loss=44115.925751 time: 32.212434
[Epoch 25] train=0.721615 val_top1=0.661900 val_top5=0.930800 loss=43022.345051 time: 31.893718
[Epoch 26] train=0.726442 val_top1=0.660600 val_top5=0.928400 loss=42470.298126 time: 32.025096
[Epoch 27] train=0.727043 val_top1=0.640200 val_top5=0.921400 loss=42023.081028 time: 31.848970
[Epoch 28] train=0.733393 val_top1=0.664700 val_top5=0.922900 loss=40982.105392 time: 32.212800
[Epoch 29] train=0.736338 val_top1=0.684900 val_top5=0.936100 loss=40856.394157 time: 32.100220
[Epoch 30] train=0.793630 val_top1=0.748500 val_top5=0.957800 loss=31892.382118 time: 32.164596
[Epoch 31] train=0.822356 val_top1=0.752600 val_top5=0.958400 loss=27564.308033 time: 32.096462
[Epoch 32] train=0.830128 val_top1=0.753800 val_top5=0.959400 loss=26237.690189 time: 31.953799
[Epoch 33] train=0.837059 val_top1=0.757100 val_top5=0.959800 loss=25053.787289 time: 31.729101
[Epoch 34] train=0.843349 val_top1=0.754900 val_top5=0.960500 loss=24156.261242 time: 32.140452
[Epoch 35] train=0.844611 val_top1=0.755600 val_top5=0.959100 loss=23703.596294 time: 32.092684
[Epoch 36] train=0.847536 val_top1=0.758300 val_top5=0.959500 loss=22977.633530 time: 32.048733
[Epoch 37] train=0.851683 val_top1=0.755100 val_top5=0.959800 loss=22542.923927 time: 32.009078
[Epoch 38] train=0.856070 val_top1=0.758700 val_top5=0.956800 loss=21987.679916 time: 32.032284
[Epoch 39] train=0.859215 val_top1=0.756000 val_top5=0.960000 loss=21435.443754 time: 32.082757
[Epoch 40] train=0.862059 val_top1=0.756600 val_top5=0.959100 loss=21005.585922 time: 32.043850
[Epoch 41] train=0.865164 val_top1=0.754400 val_top5=0.958100 loss=20670.414413 time: 32.169110
[Epoch 42] train=0.868109 val_top1=0.756600 val_top5=0.959000 loss=20049.132303 time: 32.234062
[Epoch 43] train=0.871034 val_top1=0.753700 val_top5=0.957400 loss=19598.519295 time: 31.996667
[Epoch 44] train=0.873177 val_top1=0.751000 val_top5=0.955700 loss=19351.531761 time: 32.257996
[Epoch 45] train=0.874780 val_top1=0.756400 val_top5=0.958300 loss=18869.800049 time: 32.065269
[Epoch 46] train=0.878265 val_top1=0.754000 val_top5=0.958000 loss=18384.069252 time: 32.209276
[Epoch 47] train=0.877524 val_top1=0.751900 val_top5=0.957000 loss=18333.057390 time: 31.846315
[Epoch 48] train=0.878726 val_top1=0.753900 val_top5=0.956800 loss=18164.476542 time: 32.128789
[Epoch 49] train=0.882051 val_top1=0.750600 val_top5=0.956300 loss=17698.554588 time: 31.984986
[Epoch 50] train=0.887460 val_top1=0.751600 val_top5=0.957100 loss=17143.316429 time: 31.997274
[Epoch 51] train=0.889263 val_top1=0.745400 val_top5=0.955500 loss=16785.781387 time: 31.991395
[Epoch 52] train=0.888682 val_top1=0.752500 val_top5=0.955400 loss=16626.093487 time: 32.082557
[Epoch 53] train=0.892328 val_top1=0.748000 val_top5=0.957500 loss=16242.140509 time: 32.191869
[Epoch 54] train=0.892388 val_top1=0.746600 val_top5=0.957300 loss=16138.764967 time: 32.111999
[Epoch 55] train=0.895052 val_top1=0.750400 val_top5=0.957900 loss=15770.977274 time: 31.937901
[Epoch 56] train=0.897616 val_top1=0.745400 val_top5=0.956100 loss=15550.487524 time: 31.936642
[Epoch 57] train=0.899018 val_top1=0.750900 val_top5=0.956600 loss=15135.631075 time: 32.080050
[Epoch 58] train=0.899920 val_top1=0.750800 val_top5=0.956500 loss=15104.302359 time: 31.941350
[Epoch 59] train=0.900060 val_top1=0.748500 val_top5=0.957700 loss=14782.358935 time: 32.053200
[Epoch 60] train=0.914764 val_top1=0.754500 val_top5=0.959700 loss=12949.682720 time: 31.854556
[Epoch 61] train=0.920573 val_top1=0.756400 val_top5=0.958200 loss=12080.941782 time: 32.023118
[Epoch 62] train=0.923558 val_top1=0.756200 val_top5=0.958300 loss=11632.313279 time: 32.155506
[Epoch 63] train=0.924659 val_top1=0.760200 val_top5=0.960200 loss=11620.273955 time: 31.953842
[Epoch 64] train=0.926362 val_top1=0.760000 val_top5=0.958400 loss=11273.161618 time: 32.124734
[Epoch 65] train=0.925761 val_top1=0.757800 val_top5=0.958700 loss=11333.890206 time: 31.895453
[Epoch 66] train=0.927704 val_top1=0.758400 val_top5=0.957700 loss=11160.938965 time: 31.888940
[Epoch 67] train=0.928866 val_top1=0.758500 val_top5=0.957800 loss=10928.348942 time: 31.956753
[Epoch 68] train=0.931190 val_top1=0.758900 val_top5=0.958100 loss=10612.404555 time: 32.003758
[Epoch 69] train=0.929447 val_top1=0.760000 val_top5=0.957100 loss=10782.912429 time: 32.041338
[Epoch 70] train=0.932091 val_top1=0.758400 val_top5=0.959400 loss=10546.957464 time: 32.162180
[Epoch 71] train=0.931611 val_top1=0.758900 val_top5=0.958500 loss=10614.424212 time: 32.086506
[Epoch 72] train=0.930288 val_top1=0.761200 val_top5=0.958500 loss=10768.440856 time: 32.207772
[Epoch 73] train=0.932732 val_top1=0.762100 val_top5=0.958100 loss=10538.245952 time: 31.945273
[Epoch 74] train=0.932772 val_top1=0.760500 val_top5=0.958200 loss=10456.416628 time: 32.440776
[Epoch 75] train=0.933153 val_top1=0.760500 val_top5=0.957100 loss=10439.257806 time: 32.033460
[Epoch 76] train=0.931671 val_top1=0.757400 val_top5=0.958000 loss=10323.781839 time: 32.162899
[Epoch 77] train=0.934635 val_top1=0.760800 val_top5=0.956300 loss=10158.476209 time: 32.070933
[Epoch 78] train=0.934796 val_top1=0.760100 val_top5=0.959100 loss=10131.188779 time: 31.747828
[Epoch 79] train=0.935056 val_top1=0.760000 val_top5=0.957300 loss=10002.126400 time: 32.090431
[Epoch 80] train=0.936458 val_top1=0.760300 val_top5=0.958600 loss=9860.783141 time: 32.111180
[Epoch 81] train=0.935437 val_top1=0.759900 val_top5=0.958500 loss=9978.400995 time: 32.180369
[Epoch 82] train=0.934235 val_top1=0.759000 val_top5=0.958200 loss=10047.514709 time: 32.305862
[Epoch 83] train=0.935016 val_top1=0.758800 val_top5=0.958000 loss=9892.379958 time: 32.104260
[Epoch 84] train=0.933614 val_top1=0.757200 val_top5=0.957400 loss=10122.606210 time: 31.908172
[Epoch 85] train=0.936558 val_top1=0.758500 val_top5=0.958900 loss=9744.551847 time: 32.233310
[Epoch 86] train=0.935877 val_top1=0.758500 val_top5=0.957200 loss=9837.927859 time: 31.992693
[Epoch 87] train=0.936098 val_top1=0.762000 val_top5=0.958500 loss=9658.928736 time: 32.014135
[Epoch 88] train=0.938982 val_top1=0.760700 val_top5=0.957100 loss=9454.539456 time: 32.030025
[Epoch 89] train=0.938101 val_top1=0.760600 val_top5=0.958000 loss=9551.171006 time: 31.784138
[Epoch 90] train=0.939243 val_top1=0.761400 val_top5=0.959000 loss=9399.942828 time: 31.666246
[Epoch 91] train=0.939363 val_top1=0.760000 val_top5=0.958400 loss=9461.088717 time: 32.016173
[Epoch 92] train=0.941286 val_top1=0.761300 val_top5=0.958700 loss=9227.667949 time: 31.916528
[Epoch 93] train=0.941186 val_top1=0.760000 val_top5=0.958500 loss=9234.264949 time: 31.955111
[Epoch 94] train=0.939964 val_top1=0.761300 val_top5=0.958700 loss=9218.306996 time: 32.081828
[Epoch 95] train=0.938061 val_top1=0.759500 val_top5=0.959200 loss=9380.613387 time: 32.051479
[Epoch 96] train=0.941226 val_top1=0.760500 val_top5=0.958900 loss=9149.945818 time: 32.050033
[Epoch 97] train=0.939383 val_top1=0.759700 val_top5=0.959500 loss=9308.016113 time: 31.894941
[Epoch 98] train=0.940044 val_top1=0.760300 val_top5=0.958900 loss=9247.070662 time: 31.996900
[Epoch 99] train=0.942388 val_top1=0.760500 val_top5=0.959200 loss=9135.256989 time: 31.848468
[Epoch 100] train=0.940425 val_top1=0.759100 val_top5=0.958800 loss=9257.373599 time: 31.795678
[Epoch 101] train=0.940825 val_top1=0.760000 val_top5=0.959500 loss=9135.216206 time: 31.936912
[Epoch 102] train=0.941887 val_top1=0.759300 val_top5=0.959000 loss=9077.370018 time: 31.909936
[Epoch 103] train=0.941206 val_top1=0.761100 val_top5=0.958300 loss=9142.745827 time: 32.026003
[Epoch 104] train=0.940184 val_top1=0.761500 val_top5=0.958900 loss=9237.608606 time: 32.002603
[Epoch 105] train=0.942648 val_top1=0.761900 val_top5=0.958700 loss=8991.071724 time: 32.328103
[Epoch 106] train=0.942588 val_top1=0.761900 val_top5=0.959000 loss=9084.855345 time: 31.999391
[Epoch 107] train=0.941066 val_top1=0.761300 val_top5=0.958800 loss=9111.573508 time: 31.832060
[Epoch 108] train=0.942187 val_top1=0.759800 val_top5=0.958200 loss=8997.444490 time: 31.867606
[Epoch 109] train=0.941266 val_top1=0.759000 val_top5=0.958200 loss=9147.018281 time: 32.026195
[Epoch 110] train=0.940284 val_top1=0.760800 val_top5=0.958300 loss=9176.904078 time: 32.208475
[Epoch 111] train=0.941807 val_top1=0.760400 val_top5=0.958900 loss=9042.859091 time: 32.147525
[Epoch 112] train=0.940825 val_top1=0.759000 val_top5=0.959200 loss=9107.752882 time: 32.026495
[Epoch 113] train=0.939503 val_top1=0.760300 val_top5=0.958300 loss=9318.318643 time: 32.228942
[Epoch 114] train=0.940805 val_top1=0.761100 val_top5=0.958700 loss=9089.776213 time: 32.039687
[Epoch 115] train=0.941727 val_top1=0.759900 val_top5=0.958500 loss=9092.877550 time: 32.147833
[Epoch 116] train=0.941006 val_top1=0.759700 val_top5=0.958700 loss=9165.336636 time: 32.015269
[Epoch 117] train=0.940365 val_top1=0.760900 val_top5=0.959000 loss=9165.221609 time: 31.904804
[Epoch 118] train=0.941847 val_top1=0.759700 val_top5=0.959100 loss=8989.705806 time: 31.973294
[Epoch 119] train=0.942468 val_top1=0.760600 val_top5=0.958300 loss=8974.725924 time: 31.883560
Done.
