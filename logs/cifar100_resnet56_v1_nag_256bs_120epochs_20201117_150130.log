Imports successful
Model Init Done.
Preprocessing Step Successful.
Initialization of train_data and val_data successful.
Per Device Batch Size: 256
Using nag Optimizer
{'learning_rate': 0.1, 'wd': 0.0001, 'momentum': 0.9}
Training loop started for 120 epochs:
[Epoch 0] train=0.132512 val_top1=0.196700 val_top5=0.581500 loss=143699.360657 time: 31.372006
[Epoch 1] train=0.224599 val_top1=0.262700 val_top5=0.654900 loss=125832.350525 time: 31.306993
[Epoch 2] train=0.296094 val_top1=0.316600 val_top5=0.717900 loss=113396.519135 time: 31.454716
[Epoch 3] train=0.356350 val_top1=0.410900 val_top5=0.800900 loss=102716.868683 time: 31.131104
[Epoch 4] train=0.424720 val_top1=0.448300 val_top5=0.819100 loss=91598.787079 time: 32.621403
[Epoch 5] train=0.467348 val_top1=0.483100 val_top5=0.841300 loss=83847.576935 time: 31.419466
[Epoch 6] train=0.509856 val_top1=0.525000 val_top5=0.872100 loss=77439.076294 time: 31.264424
[Epoch 7] train=0.538121 val_top1=0.528300 val_top5=0.867600 loss=72494.826233 time: 31.572958
[Epoch 8] train=0.565625 val_top1=0.549300 val_top5=0.878800 loss=68232.832947 time: 31.418637
[Epoch 9] train=0.587420 val_top1=0.585600 val_top5=0.904600 loss=64464.595459 time: 31.358518
[Epoch 10] train=0.602925 val_top1=0.582600 val_top5=0.894700 loss=61704.876892 time: 31.198682
[Epoch 11] train=0.620313 val_top1=0.593600 val_top5=0.909500 loss=59114.107529 time: 31.287123
[Epoch 12] train=0.636078 val_top1=0.599200 val_top5=0.911600 loss=56592.326813 time: 31.191127
[Epoch 13] train=0.646354 val_top1=0.619100 val_top5=0.917000 loss=55015.515991 time: 31.323296
[Epoch 14] train=0.661358 val_top1=0.592800 val_top5=0.892800 loss=52713.704880 time: 32.632709
[Epoch 15] train=0.671655 val_top1=0.636000 val_top5=0.920500 loss=50861.082855 time: 31.429653
[Epoch 16] train=0.679067 val_top1=0.622600 val_top5=0.918900 loss=49794.859161 time: 31.356119
[Epoch 17] train=0.690825 val_top1=0.592600 val_top5=0.894700 loss=48183.771469 time: 31.399185
[Epoch 18] train=0.698177 val_top1=0.657400 val_top5=0.932000 loss=46794.334732 time: 31.551769
[Epoch 19] train=0.705549 val_top1=0.656600 val_top5=0.930400 loss=45581.932373 time: 31.481740
[Epoch 20] train=0.713141 val_top1=0.657100 val_top5=0.925500 loss=44157.484207 time: 31.566420
[Epoch 21] train=0.718610 val_top1=0.640100 val_top5=0.924800 loss=43298.703018 time: 31.795936
[Epoch 22] train=0.726583 val_top1=0.674500 val_top5=0.937500 loss=42183.991425 time: 31.638342
[Epoch 23] train=0.733053 val_top1=0.644500 val_top5=0.927900 loss=41077.354080 time: 31.445254
[Epoch 24] train=0.738842 val_top1=0.666500 val_top5=0.938000 loss=40151.346100 time: 31.868379
[Epoch 25] train=0.745673 val_top1=0.654200 val_top5=0.925100 loss=39204.378922 time: 31.374931
[Epoch 26] train=0.749459 val_top1=0.654100 val_top5=0.918900 loss=38510.711334 time: 31.583529
[Epoch 27] train=0.753305 val_top1=0.674100 val_top5=0.940400 loss=37858.503723 time: 31.869225
[Epoch 28] train=0.760276 val_top1=0.675700 val_top5=0.931500 loss=36684.554855 time: 31.526198
[Epoch 29] train=0.762139 val_top1=0.663700 val_top5=0.927300 loss=36719.965637 time: 31.637154
[Epoch 30] train=0.801482 val_top1=0.740200 val_top5=0.956300 loss=30802.020050 time: 31.489558
[Epoch 31] train=0.831110 val_top1=0.745800 val_top5=0.957800 loss=26099.409355 time: 31.316394
[Epoch 32] train=0.841126 val_top1=0.744500 val_top5=0.956000 loss=24533.718819 time: 31.620145
[Epoch 33] train=0.846154 val_top1=0.747700 val_top5=0.957400 loss=23587.943878 time: 31.597189
[Epoch 34] train=0.853906 val_top1=0.748000 val_top5=0.957700 loss=22645.345695 time: 31.666044
[Epoch 35] train=0.855609 val_top1=0.746700 val_top5=0.957200 loss=22199.282898 time: 31.527259
[Epoch 36] train=0.858934 val_top1=0.742500 val_top5=0.955700 loss=21726.358810 time: 31.615513
[Epoch 37] train=0.862981 val_top1=0.748200 val_top5=0.957200 loss=21081.749603 time: 31.391201
[Epoch 38] train=0.864543 val_top1=0.747200 val_top5=0.956900 loss=20680.274666 time: 31.581800
[Epoch 39] train=0.869872 val_top1=0.745000 val_top5=0.959700 loss=20056.196342 time: 31.355424
[Epoch 40] train=0.869111 val_top1=0.747700 val_top5=0.957800 loss=19829.190536 time: 31.697488
[Epoch 41] train=0.873357 val_top1=0.749700 val_top5=0.957800 loss=19439.817959 time: 33.110165
[Epoch 42] train=0.873057 val_top1=0.746700 val_top5=0.958000 loss=19225.815102 time: 31.709009
[Epoch 43] train=0.875140 val_top1=0.746600 val_top5=0.957000 loss=18940.997940 time: 31.315538
[Epoch 44] train=0.875501 val_top1=0.749500 val_top5=0.959100 loss=18800.814358 time: 31.615324
[Epoch 45] train=0.881550 val_top1=0.749200 val_top5=0.957100 loss=18073.389351 time: 31.396545
[Epoch 46] train=0.882472 val_top1=0.743400 val_top5=0.956800 loss=17689.027313 time: 31.537426
[Epoch 47] train=0.884495 val_top1=0.738600 val_top5=0.957500 loss=17360.619400 time: 31.647024
[Epoch 48] train=0.884796 val_top1=0.744900 val_top5=0.955900 loss=17333.130043 time: 31.417460
[Epoch 49] train=0.889603 val_top1=0.747100 val_top5=0.956100 loss=16737.749668 time: 31.647902
[Epoch 50] train=0.889403 val_top1=0.742600 val_top5=0.956100 loss=16705.418766 time: 31.678502
[Epoch 51] train=0.891006 val_top1=0.744200 val_top5=0.956900 loss=16593.790634 time: 31.615180
[Epoch 52] train=0.894371 val_top1=0.746600 val_top5=0.954100 loss=16136.493149 time: 31.526485
[Epoch 53] train=0.895433 val_top1=0.746900 val_top5=0.955000 loss=15910.743065 time: 31.539984
[Epoch 54] train=0.897276 val_top1=0.745200 val_top5=0.955300 loss=15602.725140 time: 31.608865
[Epoch 55] train=0.895833 val_top1=0.737900 val_top5=0.952600 loss=15636.821491 time: 31.491424
[Epoch 56] train=0.898598 val_top1=0.743400 val_top5=0.955500 loss=15176.581757 time: 31.499501
[Epoch 57] train=0.903766 val_top1=0.743000 val_top5=0.953400 loss=14681.350300 time: 31.435992
[Epoch 58] train=0.903045 val_top1=0.740800 val_top5=0.953100 loss=14794.353714 time: 31.645535
[Epoch 59] train=0.903145 val_top1=0.736000 val_top5=0.953100 loss=14461.129162 time: 31.614145
[Epoch 60] train=0.912861 val_top1=0.744100 val_top5=0.955300 loss=13267.964531 time: 31.753983
[Epoch 61] train=0.917608 val_top1=0.747100 val_top5=0.956800 loss=12709.816128 time: 31.730083
[Epoch 62] train=0.920673 val_top1=0.747400 val_top5=0.957200 loss=12215.677380 time: 31.553468
[Epoch 63] train=0.920633 val_top1=0.746500 val_top5=0.956600 loss=12171.198177 time: 31.491424
[Epoch 64] train=0.922155 val_top1=0.747900 val_top5=0.957100 loss=12002.976990 time: 32.835236
[Epoch 65] train=0.922075 val_top1=0.748100 val_top5=0.956500 loss=12091.654911 time: 31.510030
[Epoch 66] train=0.921995 val_top1=0.747200 val_top5=0.956700 loss=11911.680126 time: 31.681213
[Epoch 67] train=0.924599 val_top1=0.748100 val_top5=0.956600 loss=11749.070175 time: 31.429353
[Epoch 68] train=0.923678 val_top1=0.748600 val_top5=0.957400 loss=11846.284172 time: 31.575936
[Epoch 69] train=0.923918 val_top1=0.747600 val_top5=0.956000 loss=11551.970776 time: 31.562957
[Epoch 70] train=0.923878 val_top1=0.747900 val_top5=0.956700 loss=11651.683270 time: 31.490427
[Epoch 71] train=0.926082 val_top1=0.749800 val_top5=0.955900 loss=11367.967735 time: 31.433219
[Epoch 72] train=0.923798 val_top1=0.748700 val_top5=0.956500 loss=11590.608776 time: 31.505123
[Epoch 73] train=0.922877 val_top1=0.748700 val_top5=0.956600 loss=11737.616734 time: 31.608485
[Epoch 74] train=0.925962 val_top1=0.748500 val_top5=0.956400 loss=11537.405922 time: 33.125908
[Epoch 75] train=0.925441 val_top1=0.749300 val_top5=0.956500 loss=11372.496773 time: 31.678549
[Epoch 76] train=0.926923 val_top1=0.747900 val_top5=0.956500 loss=11225.100029 time: 31.623170
[Epoch 77] train=0.927183 val_top1=0.746500 val_top5=0.956600 loss=11265.352779 time: 31.646086
[Epoch 78] train=0.926182 val_top1=0.746900 val_top5=0.955500 loss=11230.482872 time: 31.593460
[Epoch 79] train=0.926683 val_top1=0.748400 val_top5=0.957500 loss=11133.841698 time: 31.687228
[Epoch 80] train=0.927244 val_top1=0.747500 val_top5=0.956500 loss=11052.617565 time: 31.700651
[Epoch 81] train=0.926803 val_top1=0.747400 val_top5=0.956200 loss=11257.240314 time: 31.671158
[Epoch 82] train=0.927905 val_top1=0.747300 val_top5=0.956700 loss=11027.043724 time: 31.729973
[Epoch 83] train=0.928125 val_top1=0.748500 val_top5=0.955900 loss=11007.697479 time: 31.709597
[Epoch 84] train=0.928926 val_top1=0.747400 val_top5=0.956400 loss=10934.503162 time: 31.543750
[Epoch 85] train=0.928746 val_top1=0.748600 val_top5=0.956600 loss=10893.533451 time: 31.567834
[Epoch 86] train=0.930068 val_top1=0.747400 val_top5=0.956400 loss=10769.907104 time: 31.697605
[Epoch 87] train=0.930569 val_top1=0.748100 val_top5=0.955600 loss=10641.921597 time: 31.808732
[Epoch 88] train=0.931871 val_top1=0.748800 val_top5=0.956000 loss=10697.460873 time: 31.716978
[Epoch 89] train=0.929968 val_top1=0.748200 val_top5=0.955700 loss=10799.408951 time: 31.752479
[Epoch 90] train=0.931390 val_top1=0.747700 val_top5=0.957000 loss=10559.818680 time: 31.844370
[Epoch 91] train=0.931070 val_top1=0.748500 val_top5=0.956300 loss=10688.617226 time: 31.683544
[Epoch 92] train=0.930248 val_top1=0.749500 val_top5=0.956600 loss=10735.556942 time: 31.551255
[Epoch 93] train=0.930889 val_top1=0.749800 val_top5=0.956400 loss=10556.248623 time: 32.888822
[Epoch 94] train=0.931530 val_top1=0.748700 val_top5=0.956600 loss=10562.296803 time: 31.626479
[Epoch 95] train=0.930349 val_top1=0.749500 val_top5=0.956500 loss=10649.648819 time: 31.544010
[Epoch 96] train=0.929788 val_top1=0.748100 val_top5=0.957000 loss=10698.010265 time: 31.552660
[Epoch 97] train=0.932071 val_top1=0.748300 val_top5=0.956400 loss=10489.268341 time: 31.688691
[Epoch 98] train=0.930469 val_top1=0.747100 val_top5=0.956400 loss=10626.809547 time: 31.516392
[Epoch 99] train=0.932392 val_top1=0.747900 val_top5=0.957000 loss=10548.440639 time: 31.489626
[Epoch 100] train=0.931010 val_top1=0.748200 val_top5=0.955700 loss=10646.054115 time: 31.412530
[Epoch 101] train=0.932853 val_top1=0.750000 val_top5=0.957000 loss=10452.228584 time: 31.726945
[Epoch 102] train=0.932071 val_top1=0.746900 val_top5=0.956700 loss=10612.370203 time: 31.652195
[Epoch 103] train=0.930469 val_top1=0.747100 val_top5=0.956700 loss=10631.903099 time: 31.375989
[Epoch 104] train=0.930849 val_top1=0.746300 val_top5=0.956300 loss=10564.574024 time: 31.604224
[Epoch 105] train=0.931090 val_top1=0.747800 val_top5=0.956700 loss=10562.277992 time: 31.686601
[Epoch 106] train=0.933313 val_top1=0.748200 val_top5=0.956600 loss=10341.274637 time: 31.751149
[Epoch 107] train=0.931170 val_top1=0.749000 val_top5=0.956300 loss=10520.258987 time: 31.426960
[Epoch 108] train=0.929988 val_top1=0.748300 val_top5=0.956500 loss=10664.803555 time: 31.546719
[Epoch 109] train=0.932232 val_top1=0.748700 val_top5=0.956400 loss=10494.598068 time: 31.631973
[Epoch 110] train=0.933013 val_top1=0.748900 val_top5=0.956100 loss=10319.415487 time: 31.718221
[Epoch 111] train=0.932772 val_top1=0.748100 val_top5=0.956400 loss=10382.276920 time: 31.680277
[Epoch 112] train=0.933013 val_top1=0.747200 val_top5=0.957100 loss=10391.765692 time: 31.501155
[Epoch 113] train=0.932111 val_top1=0.747700 val_top5=0.957000 loss=10581.653130 time: 31.565550
[Epoch 114] train=0.930409 val_top1=0.749000 val_top5=0.956600 loss=10519.660137 time: 31.423041
[Epoch 115] train=0.932532 val_top1=0.748400 val_top5=0.956400 loss=10413.142242 time: 31.703718
[Epoch 116] train=0.931230 val_top1=0.747800 val_top5=0.956100 loss=10420.794170 time: 31.640693
[Epoch 117] train=0.932252 val_top1=0.748600 val_top5=0.956600 loss=10435.589619 time: 33.149305
[Epoch 118] train=0.932372 val_top1=0.748000 val_top5=0.956000 loss=10374.521696 time: 31.810278
[Epoch 119] train=0.931631 val_top1=0.749200 val_top5=0.956600 loss=10519.705345 time: 31.867682
Done.
