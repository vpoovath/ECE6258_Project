Imports successful
Model Init Done.
Dense(None -> 100, linear)
Teacher Model Init Done!
Preprocessing Step Successful.
Initialization of train_data and val_data successful.
sparse label loss: False
Training Settings Set Successfully.
Training loop started:
[Epoch 0] train=1.000000 val_top1=0.110900 val_top5=0.402300 loss=46075823.289062 time: 108.485758
[Epoch 1] train=1.000000 val_top1=0.195100 val_top5=0.535400 loss=46062972.992188 time: 101.721912
[Epoch 2] train=1.000000 val_top1=0.255900 val_top5=0.612500 loss=46058827.375000 time: 101.686329
[Epoch 3] train=1.000000 val_top1=0.320300 val_top5=0.682600 loss=46055045.132812 time: 101.709487
[Epoch 4] train=1.000000 val_top1=0.356400 val_top5=0.737500 loss=46051440.203125 time: 101.613663
[Epoch 5] train=1.000000 val_top1=0.383500 val_top5=0.751700 loss=46047865.609375 time: 101.604540
[Epoch 6] train=1.000000 val_top1=0.399100 val_top5=0.761600 loss=46045346.812500 time: 101.799434
[Epoch 7] train=1.000000 val_top1=0.477900 val_top5=0.829600 loss=46043153.835938 time: 101.628182
[Epoch 8] train=1.000000 val_top1=0.502700 val_top5=0.847800 loss=46042369.257812 time: 101.508516
[Epoch 9] train=1.000000 val_top1=0.523100 val_top5=0.830100 loss=46040337.179688 time: 101.835709
[Epoch 10] train=1.000000 val_top1=0.509900 val_top5=0.834500 loss=46038051.773438 time: 101.762215
[Epoch 11] train=1.000000 val_top1=0.523300 val_top5=0.850400 loss=46037077.398438 time: 101.660787
[Epoch 12] train=1.000000 val_top1=0.562300 val_top5=0.865500 loss=46035118.328125 time: 101.898290
[Epoch 13] train=1.000000 val_top1=0.569000 val_top5=0.876800 loss=46035624.015625 time: 101.897222
[Epoch 14] train=1.000000 val_top1=0.564100 val_top5=0.876600 loss=46034005.460938 time: 101.674170
[Epoch 15] train=1.000000 val_top1=0.606000 val_top5=0.882400 loss=46032440.195312 time: 101.694392
[Epoch 16] train=1.000000 val_top1=0.591900 val_top5=0.896100 loss=46032054.945312 time: 101.396802
[Epoch 17] train=1.000000 val_top1=0.614100 val_top5=0.899200 loss=46030689.585938 time: 101.847586
[Epoch 18] train=1.000000 val_top1=0.607800 val_top5=0.891500 loss=46030492.984375 time: 101.890048
[Epoch 19] train=1.000000 val_top1=0.626300 val_top5=0.894700 loss=46030981.789062 time: 101.722794
[Epoch 20] train=1.000000 val_top1=0.640200 val_top5=0.905300 loss=46030855.929688 time: 101.455019
[Epoch 21] train=1.000000 val_top1=0.626100 val_top5=0.898200 loss=46029432.960938 time: 101.764174
[Epoch 22] train=1.000000 val_top1=0.630200 val_top5=0.905200 loss=46028812.648438 time: 101.744788
[Epoch 23] train=1.000000 val_top1=0.647100 val_top5=0.910300 loss=46029285.843750 time: 101.694910
[Epoch 24] train=1.000000 val_top1=0.649800 val_top5=0.913000 loss=46027884.414062 time: 101.684186
[Epoch 25] train=1.000000 val_top1=0.644200 val_top5=0.901800 loss=46027845.617188 time: 101.786754
[Epoch 26] train=1.000000 val_top1=0.663900 val_top5=0.913300 loss=46028473.710938 time: 101.702174
[Epoch 27] train=1.000000 val_top1=0.658100 val_top5=0.913600 loss=46027532.289062 time: 101.724114
[Epoch 28] train=1.000000 val_top1=0.654800 val_top5=0.905500 loss=46028844.203125 time: 101.593925
[Epoch 29] train=1.000000 val_top1=0.585400 val_top5=0.857200 loss=46026765.312500 time: 101.767645
[Epoch 30] train=1.000000 val_top1=0.659500 val_top5=0.912800 loss=46027780.710938 time: 101.652752
[Epoch 31] train=1.000000 val_top1=0.655900 val_top5=0.906600 loss=46026566.265625 time: 101.683253
[Epoch 32] train=1.000000 val_top1=0.660700 val_top5=0.903700 loss=46025558.984375 time: 101.831633
[Epoch 33] train=1.000000 val_top1=0.666300 val_top5=0.915900 loss=46026732.835938 time: 101.845098
[Epoch 34] train=1.000000 val_top1=0.678900 val_top5=0.922700 loss=46026266.851562 time: 101.834589
[Epoch 35] train=1.000000 val_top1=0.691100 val_top5=0.921700 loss=46026566.921875 time: 101.744494
[Epoch 36] train=1.000000 val_top1=0.685000 val_top5=0.920800 loss=46025515.179688 time: 101.778152
[Epoch 37] train=1.000000 val_top1=0.623900 val_top5=0.886900 loss=46025276.609375 time: 101.400449
[Epoch 38] train=1.000000 val_top1=0.670200 val_top5=0.904800 loss=46024882.195312 time: 101.741181
[Epoch 39] train=1.000000 val_top1=0.674000 val_top5=0.911500 loss=46025569.171875 time: 101.677184
[Epoch 40] train=1.000000 val_top1=0.695700 val_top5=0.931900 loss=46024676.148438 time: 101.397202
[Epoch 41] train=1.000000 val_top1=0.645800 val_top5=0.908100 loss=46025655.109375 time: 101.772449
[Epoch 42] train=1.000000 val_top1=0.686900 val_top5=0.923100 loss=46025044.468750 time: 101.656676
[Epoch 43] train=1.000000 val_top1=0.665200 val_top5=0.920000 loss=46023295.875000 time: 101.564538
[Epoch 44] train=1.000000 val_top1=0.684600 val_top5=0.912300 loss=46024262.250000 time: 101.932033
[Epoch 45] train=1.000000 val_top1=0.691400 val_top5=0.925200 loss=46023937.460938 time: 101.928679
[Epoch 46] train=1.000000 val_top1=0.692700 val_top5=0.921700 loss=46025158.148438 time: 101.705557
[Epoch 47] train=1.000000 val_top1=0.692600 val_top5=0.912300 loss=46024032.234375 time: 101.669754
[Epoch 48] train=1.000000 val_top1=0.692200 val_top5=0.916900 loss=46023921.070312 time: 101.503265
[Epoch 49] train=1.000000 val_top1=0.668500 val_top5=0.915100 loss=46023426.867188 time: 101.594080
[Epoch 50] train=1.000000 val_top1=0.645400 val_top5=0.893600 loss=46024079.812500 time: 101.683458
[Epoch 51] train=1.000000 val_top1=0.705800 val_top5=0.927900 loss=46023795.320312 time: 101.718247
[Epoch 52] train=1.000000 val_top1=0.716200 val_top5=0.938100 loss=46024314.460938 time: 101.645363
[Epoch 53] train=1.000000 val_top1=0.686500 val_top5=0.920600 loss=46022348.929688 time: 101.449812
[Epoch 54] train=1.000000 val_top1=0.700500 val_top5=0.928300 loss=46023039.164062 time: 101.584393
[Epoch 55] train=1.000000 val_top1=0.709100 val_top5=0.934300 loss=46024453.414062 time: 101.496155
[Epoch 56] train=1.000000 val_top1=0.695700 val_top5=0.923300 loss=46023554.617188 time: 101.664902
[Epoch 57] train=1.000000 val_top1=0.713000 val_top5=0.929600 loss=46022265.210938 time: 101.925600
[Epoch 58] train=1.000000 val_top1=0.701800 val_top5=0.927100 loss=46022337.132812 time: 101.765755
[Epoch 59] train=1.000000 val_top1=0.691800 val_top5=0.911200 loss=46021693.593750 time: 101.492583
[Epoch 60] train=1.000000 val_top1=0.688100 val_top5=0.919600 loss=46020614.382812 time: 101.803814
[Epoch 61] train=1.000000 val_top1=0.697400 val_top5=0.931600 loss=46022077.601562 time: 101.663704
[Epoch 62] train=1.000000 val_top1=0.688800 val_top5=0.923600 loss=46021978.914062 time: 101.623554
[Epoch 63] train=1.000000 val_top1=0.704500 val_top5=0.925500 loss=46022930.843750 time: 101.692332
[Epoch 64] train=1.000000 val_top1=0.671500 val_top5=0.904200 loss=46021616.757812 time: 101.834307
[Epoch 65] train=1.000000 val_top1=0.718800 val_top5=0.928100 loss=46021862.320312 time: 101.709269
[Epoch 66] train=1.000000 val_top1=0.723700 val_top5=0.933500 loss=46022193.992188 time: 101.836133
[Epoch 67] train=1.000000 val_top1=0.690500 val_top5=0.915400 loss=46021577.648438 time: 101.585582
[Epoch 68] train=1.000000 val_top1=0.707600 val_top5=0.922300 loss=46022778.882812 time: 101.658121
[Epoch 69] train=1.000000 val_top1=0.704500 val_top5=0.928000 loss=46020484.789062 time: 101.779620
[Epoch 70] train=1.000000 val_top1=0.712000 val_top5=0.927200 loss=46021511.578125 time: 101.626508
[Epoch 71] train=1.000000 val_top1=0.697800 val_top5=0.911100 loss=46020877.914062 time: 101.536152
[Epoch 72] train=1.000000 val_top1=0.721600 val_top5=0.937200 loss=46020616.984375 time: 101.807918
[Epoch 73] train=1.000000 val_top1=0.723300 val_top5=0.930600 loss=46021934.804688 time: 101.821393
[Epoch 74] train=1.000000 val_top1=0.692700 val_top5=0.913600 loss=46021092.757812 time: 101.675543
[Epoch 75] train=1.000000 val_top1=0.705000 val_top5=0.926700 loss=46021661.851562 time: 101.844923
[Epoch 76] train=1.000000 val_top1=0.724300 val_top5=0.934700 loss=46021038.562500 time: 101.782853
[Epoch 77] train=1.000000 val_top1=0.717500 val_top5=0.929800 loss=46022064.500000 time: 101.835870
[Epoch 78] train=1.000000 val_top1=0.713800 val_top5=0.917800 loss=46020561.718750 time: 101.679569
[Epoch 79] train=1.000000 val_top1=0.723100 val_top5=0.926300 loss=46019685.906250 time: 101.639586
[Epoch 80] train=1.000000 val_top1=0.706500 val_top5=0.922600 loss=46019993.664062 time: 101.760328
[Epoch 81] train=1.000000 val_top1=0.690700 val_top5=0.918100 loss=46019146.382812 time: 101.546507
[Epoch 82] train=1.000000 val_top1=0.716500 val_top5=0.929900 loss=46020754.656250 time: 101.705166
[Epoch 83] train=1.000000 val_top1=0.712300 val_top5=0.927500 loss=46019441.710938 time: 101.964461
[Epoch 84] train=1.000000 val_top1=0.721100 val_top5=0.928000 loss=46019150.648438 time: 101.994753
[Epoch 85] train=1.000000 val_top1=0.714400 val_top5=0.926300 loss=46020423.062500 time: 101.874801
[Epoch 86] train=1.000000 val_top1=0.715800 val_top5=0.929000 loss=46019481.640625 time: 101.668652
[Epoch 87] train=1.000000 val_top1=0.720300 val_top5=0.936100 loss=46020224.390625 time: 102.014734
[Epoch 88] train=1.000000 val_top1=0.713800 val_top5=0.923400 loss=46018467.046875 time: 101.768093
[Epoch 89] train=1.000000 val_top1=0.723400 val_top5=0.925000 loss=46018691.406250 time: 101.847581
[Epoch 90] train=1.000000 val_top1=0.729500 val_top5=0.927900 loss=46019085.093750 time: 101.741192
[Epoch 91] train=1.000000 val_top1=0.707400 val_top5=0.909400 loss=46020156.257812 time: 101.775677
[Epoch 92] train=1.000000 val_top1=0.724400 val_top5=0.927000 loss=46019100.226562 time: 101.769773
[Epoch 93] train=1.000000 val_top1=0.730300 val_top5=0.929200 loss=46019788.750000 time: 101.658095
[Epoch 94] train=1.000000 val_top1=0.735100 val_top5=0.931300 loss=46019952.562500 time: 101.849062
[Epoch 95] train=1.000000 val_top1=0.736000 val_top5=0.930200 loss=46017133.648438 time: 101.716057
[Epoch 96] train=1.000000 val_top1=0.722500 val_top5=0.930400 loss=46019176.484375 time: 101.621011
[Epoch 97] train=1.000000 val_top1=0.731500 val_top5=0.934900 loss=46019002.109375 time: 101.628333
[Epoch 98] train=1.000000 val_top1=0.724100 val_top5=0.928900 loss=46019724.390625 time: 101.823674
[Epoch 99] train=1.000000 val_top1=0.753700 val_top5=0.939100 loss=46019652.945312 time: 101.694314
[Epoch 100] train=1.000000 val_top1=0.726600 val_top5=0.927500 loss=46019427.187500 time: 101.863896
[Epoch 101] train=1.000000 val_top1=0.735300 val_top5=0.924500 loss=46017828.750000 time: 101.758410
[Epoch 102] train=1.000000 val_top1=0.715600 val_top5=0.917700 loss=46017239.335938 time: 101.796026
[Epoch 103] train=1.000000 val_top1=0.739500 val_top5=0.931300 loss=46016881.781250 time: 101.721824
[Epoch 104] train=1.000000 val_top1=0.732100 val_top5=0.930600 loss=46017031.234375 time: 101.577131
[Epoch 105] train=1.000000 val_top1=0.740300 val_top5=0.928200 loss=46017814.046875 time: 101.781263
[Epoch 106] train=1.000000 val_top1=0.738100 val_top5=0.937500 loss=46016980.429688 time: 101.807689
[Epoch 107] train=1.000000 val_top1=0.735500 val_top5=0.929100 loss=46016663.015625 time: 101.637644
[Epoch 108] train=1.000000 val_top1=0.713200 val_top5=0.911800 loss=46017621.914062 time: 101.768166
[Epoch 109] train=1.000000 val_top1=0.741800 val_top5=0.933500 loss=46018497.117188 time: 101.584288
[Epoch 110] train=1.000000 val_top1=0.729800 val_top5=0.931700 loss=46017362.828125 time: 101.791894
[Epoch 111] train=1.000000 val_top1=0.737600 val_top5=0.933600 loss=46018599.843750 time: 101.771643
[Epoch 112] train=1.000000 val_top1=0.743900 val_top5=0.940300 loss=46017972.062500 time: 101.529949
[Epoch 113] train=1.000000 val_top1=0.744300 val_top5=0.926500 loss=46017599.679688 time: 101.727630
[Epoch 114] train=1.000000 val_top1=0.747200 val_top5=0.935600 loss=46016343.984375 time: 101.762539
[Epoch 115] train=1.000000 val_top1=0.743400 val_top5=0.937900 loss=46016771.187500 time: 101.790895
[Epoch 116] train=1.000000 val_top1=0.752000 val_top5=0.942800 loss=46017142.773438 time: 101.729315
[Epoch 117] train=1.000000 val_top1=0.742200 val_top5=0.927500 loss=46015104.906250 time: 101.997557
[Epoch 118] train=1.000000 val_top1=0.741600 val_top5=0.929800 loss=46016031.406250 time: 101.884743
[Epoch 119] train=1.000000 val_top1=0.745900 val_top5=0.934500 loss=46016667.703125 time: 101.688828
[Epoch 120] train=1.000000 val_top1=0.755800 val_top5=0.935900 loss=46017782.976562 time: 101.769641
[Epoch 121] train=1.000000 val_top1=0.728700 val_top5=0.927900 loss=46015912.375000 time: 101.883211
[Epoch 122] train=1.000000 val_top1=0.753700 val_top5=0.936800 loss=46015662.867188 time: 101.728508
[Epoch 123] train=1.000000 val_top1=0.735200 val_top5=0.930700 loss=46015463.507812 time: 101.783556
[Epoch 124] train=1.000000 val_top1=0.742100 val_top5=0.934100 loss=46014338.062500 time: 101.697392
[Epoch 125] train=1.000000 val_top1=0.750800 val_top5=0.929900 loss=46016405.632812 time: 101.581492
[Epoch 126] train=1.000000 val_top1=0.758900 val_top5=0.938500 loss=46014335.789062 time: 101.723262
[Epoch 127] train=1.000000 val_top1=0.757800 val_top5=0.937400 loss=46016537.664062 time: 101.843721
[Epoch 128] train=1.000000 val_top1=0.758900 val_top5=0.938700 loss=46015183.539062 time: 101.489143
[Epoch 129] train=1.000000 val_top1=0.760900 val_top5=0.939200 loss=46016704.304688 time: 101.934544
[Epoch 130] train=1.000000 val_top1=0.742300 val_top5=0.925200 loss=46015834.156250 time: 101.759368
[Epoch 131] train=1.000000 val_top1=0.766200 val_top5=0.934300 loss=46013716.390625 time: 101.929031
[Epoch 132] train=1.000000 val_top1=0.759200 val_top5=0.938100 loss=46015055.187500 time: 101.931481
[Epoch 133] train=1.000000 val_top1=0.754800 val_top5=0.938200 loss=46013250.406250 time: 101.866963
[Epoch 134] train=1.000000 val_top1=0.759100 val_top5=0.934600 loss=46013220.718750 time: 101.681838
[Epoch 135] train=1.000000 val_top1=0.760900 val_top5=0.928400 loss=46013474.046875 time: 101.912868
[Epoch 136] train=1.000000 val_top1=0.753500 val_top5=0.928000 loss=46013366.007812 time: 101.682946
[Epoch 137] train=1.000000 val_top1=0.754300 val_top5=0.932000 loss=46013421.023438 time: 101.738264
[Epoch 138] train=1.000000 val_top1=0.769800 val_top5=0.934600 loss=46012855.218750 time: 101.892088
[Epoch 139] train=1.000000 val_top1=0.761700 val_top5=0.935200 loss=46013359.632812 time: 101.739494
[Epoch 140] train=1.000000 val_top1=0.772700 val_top5=0.935900 loss=46013872.906250 time: 101.747833
[Epoch 141] train=1.000000 val_top1=0.767300 val_top5=0.940100 loss=46015986.023438 time: 101.804706
[Epoch 142] train=1.000000 val_top1=0.764400 val_top5=0.929300 loss=46013405.445312 time: 101.811975
[Epoch 143] train=1.000000 val_top1=0.771500 val_top5=0.929000 loss=46011493.648438 time: 101.871115
[Epoch 144] train=1.000000 val_top1=0.768800 val_top5=0.935100 loss=46011798.320312 time: 101.776209
[Epoch 145] train=1.000000 val_top1=0.761700 val_top5=0.930800 loss=46011933.585938 time: 101.558847
[Epoch 146] train=1.000000 val_top1=0.763900 val_top5=0.933100 loss=46011049.882812 time: 101.544110
[Epoch 147] train=1.000000 val_top1=0.769700 val_top5=0.934700 loss=46011030.171875 time: 101.880208
[Epoch 148] train=1.000000 val_top1=0.777800 val_top5=0.937000 loss=46012924.882812 time: 102.186852
[Epoch 149] train=1.000000 val_top1=0.778700 val_top5=0.936600 loss=46012254.429688 time: 102.169421
[Epoch 150] train=1.000000 val_top1=0.773000 val_top5=0.935200 loss=46010497.023438 time: 101.683580
[Epoch 151] train=1.000000 val_top1=0.777400 val_top5=0.935800 loss=46011652.101562 time: 101.818209
[Epoch 152] train=1.000000 val_top1=0.776900 val_top5=0.934200 loss=46012861.007812 time: 101.740030
[Epoch 153] train=1.000000 val_top1=0.781000 val_top5=0.933800 loss=46011836.335938 time: 101.844276
[Epoch 154] train=1.000000 val_top1=0.781600 val_top5=0.938000 loss=46012236.039062 time: 101.723240
[Epoch 155] train=1.000000 val_top1=0.780800 val_top5=0.938400 loss=46012564.484375 time: 101.451497
[Epoch 156] train=1.000000 val_top1=0.773700 val_top5=0.934600 loss=46011401.437500 time: 101.898980
[Epoch 157] train=1.000000 val_top1=0.779000 val_top5=0.933600 loss=46011225.875000 time: 101.802403
[Epoch 158] train=1.000000 val_top1=0.774900 val_top5=0.939800 loss=46010830.679688 time: 100.877046
[Epoch 159] train=1.000000 val_top1=0.785400 val_top5=0.936600 loss=46011672.500000 time: 101.655398
[Epoch 160] train=1.000000 val_top1=0.774900 val_top5=0.934500 loss=46010932.562500 time: 100.803269
[Epoch 161] train=1.000000 val_top1=0.782100 val_top5=0.932500 loss=46011461.304688 time: 100.892157
[Epoch 162] train=1.000000 val_top1=0.782900 val_top5=0.930100 loss=46010451.632812 time: 101.548702
[Epoch 163] train=1.000000 val_top1=0.787100 val_top5=0.939800 loss=46013067.562500 time: 101.666255
[Epoch 164] train=1.000000 val_top1=0.787600 val_top5=0.937400 loss=46010807.890625 time: 101.808997
[Epoch 165] train=1.000000 val_top1=0.785700 val_top5=0.936800 loss=46010636.562500 time: 101.675446
[Epoch 166] train=1.000000 val_top1=0.783100 val_top5=0.938200 loss=46010994.843750 time: 101.663698
[Epoch 167] train=1.000000 val_top1=0.780700 val_top5=0.937500 loss=46010087.554688 time: 101.671056
[Epoch 168] train=1.000000 val_top1=0.788700 val_top5=0.937700 loss=46008888.265625 time: 101.582050
[Epoch 169] train=1.000000 val_top1=0.783600 val_top5=0.935100 loss=46010038.976562 time: 101.919089
[Epoch 170] train=1.000000 val_top1=0.787300 val_top5=0.936800 loss=46009795.250000 time: 101.718720
[Epoch 171] train=1.000000 val_top1=0.792500 val_top5=0.936000 loss=46006756.710938 time: 101.762656
[Epoch 172] train=1.000000 val_top1=0.792000 val_top5=0.931100 loss=46009102.484375 time: 101.670905
[Epoch 173] train=1.000000 val_top1=0.792600 val_top5=0.935300 loss=46008713.734375 time: 101.797903
[Epoch 174] train=1.000000 val_top1=0.788800 val_top5=0.937300 loss=46009849.546875 time: 101.699906
[Epoch 175] train=1.000000 val_top1=0.788700 val_top5=0.932300 loss=46009894.460938 time: 101.561393
[Epoch 176] train=1.000000 val_top1=0.791200 val_top5=0.938600 loss=46009927.875000 time: 101.759900
[Epoch 177] train=1.000000 val_top1=0.789100 val_top5=0.935600 loss=46009549.492188 time: 101.759518
[Epoch 178] train=1.000000 val_top1=0.791300 val_top5=0.940800 loss=46009461.898438 time: 101.548173
[Epoch 179] train=1.000000 val_top1=0.789600 val_top5=0.939300 loss=46010489.343750 time: 101.558847
[Epoch 180] train=1.000000 val_top1=0.794200 val_top5=0.934900 loss=46009783.750000 time: 101.671051
[Epoch 181] train=1.000000 val_top1=0.793200 val_top5=0.935800 loss=46007551.398438 time: 101.554496
[Epoch 182] train=1.000000 val_top1=0.793600 val_top5=0.934500 loss=46009305.015625 time: 101.881424
[Epoch 183] train=1.000000 val_top1=0.793500 val_top5=0.937800 loss=46009021.953125 time: 101.643737
[Epoch 184] train=1.000000 val_top1=0.792900 val_top5=0.936900 loss=46008416.734375 time: 101.617966
[Epoch 185] train=1.000000 val_top1=0.794300 val_top5=0.937800 loss=46010371.140625 time: 101.722474
[Epoch 186] train=1.000000 val_top1=0.792200 val_top5=0.936400 loss=46008658.250000 time: 101.556410
[Epoch 187] train=1.000000 val_top1=0.791200 val_top5=0.936600 loss=46009737.648438 time: 101.588250
[Epoch 188] train=1.000000 val_top1=0.789700 val_top5=0.938500 loss=46009162.242188 time: 101.748249
[Epoch 189] train=1.000000 val_top1=0.793500 val_top5=0.936100 loss=46009054.320312 time: 101.548873
[Epoch 190] train=1.000000 val_top1=0.795900 val_top5=0.934700 loss=46007376.601562 time: 101.638093
[Epoch 191] train=1.000000 val_top1=0.797600 val_top5=0.937900 loss=46010128.789062 time: 101.782856
[Epoch 192] train=1.000000 val_top1=0.797000 val_top5=0.935800 loss=46009024.835938 time: 101.764152
[Epoch 193] train=1.000000 val_top1=0.797700 val_top5=0.933000 loss=46008363.914062 time: 101.741818
[Epoch 194] train=1.000000 val_top1=0.798400 val_top5=0.934200 loss=46008156.671875 time: 101.706549
[Epoch 195] train=1.000000 val_top1=0.797500 val_top5=0.932300 loss=46009317.882812 time: 101.697602
[Epoch 196] train=1.000000 val_top1=0.796900 val_top5=0.936900 loss=46008727.484375 time: 101.948015
[Epoch 197] train=1.000000 val_top1=0.798100 val_top5=0.935200 loss=46008828.710938 time: 101.767789
[Epoch 198] train=1.000000 val_top1=0.794200 val_top5=0.937600 loss=46009435.921875 time: 101.913804
[Epoch 199] train=1.000000 val_top1=0.797800 val_top5=0.936000 loss=46008070.781250 time: 101.561502
Done.
