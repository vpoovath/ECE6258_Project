Teacher model - cifar_resnet110_v2 with new Dense layer for 100 classes (Xavier init)
This pretrained model on the model_zoo has a top-1 accuracy of 94.3 which is a little lower than 
the model trained with everything but distillation.
TODO: Run the distillation again but with a model with higher top-1 accuracy, maybe
cifar_wideresnet28_10, cifar_wideresnet40_8, and cifar_resnext29_16x64d.

Training loop started:
[Epoch 0] train=1.000000 val_top1=0.104600 val_top5=0.398000 loss=46082944.859375 time: 58.285605
[Epoch 1] train=1.000000 val_top1=0.172000 val_top5=0.525300 loss=46071959.437500 time: 56.817250
[Epoch 2] train=1.000000 val_top1=0.256500 val_top5=0.644000 loss=46067837.453125 time: 56.433728
[Epoch 3] train=1.000000 val_top1=0.305800 val_top5=0.698700 loss=46064250.765625 time: 55.840825
[Epoch 4] train=1.000000 val_top1=0.336200 val_top5=0.722500 loss=46060673.585938 time: 55.602539
[Epoch 5] train=1.000000 val_top1=0.376200 val_top5=0.753900 loss=46057972.929688 time: 57.089852
[Epoch 6] train=1.000000 val_top1=0.450900 val_top5=0.821200 loss=46054848.710938 time: 56.507239
[Epoch 7] train=1.000000 val_top1=0.459800 val_top5=0.827800 loss=46052723.140625 time: 57.239414
[Epoch 8] train=1.000000 val_top1=0.496700 val_top5=0.848300 loss=46049993.859375 time: 57.927612
[Epoch 9] train=1.000000 val_top1=0.483200 val_top5=0.835800 loss=46049375.804688 time: 57.485024
[Epoch 10] train=1.000000 val_top1=0.498700 val_top5=0.858200 loss=46047318.398438 time: 57.801224
[Epoch 11] train=1.000000 val_top1=0.503500 val_top5=0.829600 loss=46045047.640625 time: 57.481338
[Epoch 12] train=1.000000 val_top1=0.587700 val_top5=0.895700 loss=46045398.726562 time: 57.950269
[Epoch 13] train=1.000000 val_top1=0.572600 val_top5=0.886500 loss=46043351.468750 time: 59.258366
[Epoch 14] train=1.000000 val_top1=0.583600 val_top5=0.892200 loss=46042496.757812 time: 56.884080
[Epoch 15] train=1.000000 val_top1=0.589400 val_top5=0.892400 loss=46041797.562500 time: 58.369841
[Epoch 16] train=1.000000 val_top1=0.615500 val_top5=0.907500 loss=46040533.320312 time: 56.953508
[Epoch 17] train=1.000000 val_top1=0.597400 val_top5=0.904400 loss=46040548.921875 time: 56.995831
[Epoch 18] train=1.000000 val_top1=0.627400 val_top5=0.916300 loss=46039394.609375 time: 55.705610
[Epoch 19] train=1.000000 val_top1=0.643900 val_top5=0.918500 loss=46039624.796875 time: 56.552298
[Epoch 20] train=1.000000 val_top1=0.605400 val_top5=0.897800 loss=46039037.140625 time: 56.042441
[Epoch 21] train=1.000000 val_top1=0.610700 val_top5=0.899400 loss=46039019.914062 time: 56.728081
[Epoch 22] train=1.000000 val_top1=0.607600 val_top5=0.911600 loss=46038314.039062 time: 55.784868
[Epoch 23] train=1.000000 val_top1=0.627100 val_top5=0.907700 loss=46036918.687500 time: 55.986581
[Epoch 24] train=1.000000 val_top1=0.669600 val_top5=0.929400 loss=46036289.390625 time: 56.283541
[Epoch 25] train=1.000000 val_top1=0.654900 val_top5=0.921500 loss=46036839.000000 time: 55.597055
[Epoch 26] train=1.000000 val_top1=0.656700 val_top5=0.918500 loss=46036157.453125 time: 56.486969
[Epoch 27] train=1.000000 val_top1=0.677100 val_top5=0.934500 loss=46034811.468750 time: 55.429002
[Epoch 28] train=1.000000 val_top1=0.667100 val_top5=0.924300 loss=46035811.882812 time: 56.968077
[Epoch 29] train=1.000000 val_top1=0.665400 val_top5=0.918900 loss=46034961.828125 time: 57.780487
[Epoch 30] train=1.000000 val_top1=0.671000 val_top5=0.926900 loss=46035946.718750 time: 57.566835
[Epoch 31] train=1.000000 val_top1=0.667200 val_top5=0.925700 loss=46035299.062500 time: 57.588453
[Epoch 32] train=1.000000 val_top1=0.676500 val_top5=0.928800 loss=46034893.125000 time: 57.526914
[Epoch 33] train=1.000000 val_top1=0.682400 val_top5=0.929600 loss=46034883.289062 time: 57.969398
[Epoch 34] train=1.000000 val_top1=0.689800 val_top5=0.937100 loss=46034502.593750 time: 58.028217
[Epoch 35] train=1.000000 val_top1=0.639800 val_top5=0.910900 loss=46033936.648438 time: 58.313949
[Epoch 36] train=1.000000 val_top1=0.652200 val_top5=0.919000 loss=46033010.031250 time: 57.564298
[Epoch 37] train=1.000000 val_top1=0.684100 val_top5=0.933400 loss=46034480.750000 time: 58.065912
[Epoch 38] train=1.000000 val_top1=0.669300 val_top5=0.923200 loss=46034271.734375 time: 57.640795
[Epoch 39] train=1.000000 val_top1=0.681700 val_top5=0.931700 loss=46032996.523438 time: 57.129656
[Epoch 40] train=1.000000 val_top1=0.684000 val_top5=0.928600 loss=46034424.070312 time: 56.409740
[Epoch 41] train=1.000000 val_top1=0.649000 val_top5=0.918700 loss=46033398.460938 time: 55.886757
[Epoch 42] train=1.000000 val_top1=0.665800 val_top5=0.925800 loss=46033555.218750 time: 55.492010
[Epoch 43] train=1.000000 val_top1=0.684600 val_top5=0.932300 loss=46033496.312500 time: 55.570511
[Epoch 44] train=1.000000 val_top1=0.701300 val_top5=0.936100 loss=46033127.585938 time: 56.968038
[Epoch 45] train=1.000000 val_top1=0.679900 val_top5=0.928800 loss=46032888.406250 time: 56.033205
[Epoch 46] train=1.000000 val_top1=0.672300 val_top5=0.923100 loss=46032612.312500 time: 56.100686
[Epoch 47] train=1.000000 val_top1=0.675800 val_top5=0.921100 loss=46031871.421875 time: 55.858379
[Epoch 48] train=1.000000 val_top1=0.697800 val_top5=0.939200 loss=46032353.867188 time: 55.913509
[Epoch 49] train=1.000000 val_top1=0.696100 val_top5=0.928800 loss=46032227.039062 time: 56.548575
[Epoch 50] train=1.000000 val_top1=0.693200 val_top5=0.938400 loss=46032829.382812 time: 56.544713
[Epoch 51] train=1.000000 val_top1=0.672000 val_top5=0.923900 loss=46032105.898438 time: 56.313571
[Epoch 52] train=1.000000 val_top1=0.706600 val_top5=0.939200 loss=46032400.054688 time: 56.694284
[Epoch 53] train=1.000000 val_top1=0.690100 val_top5=0.937000 loss=46032400.164062 time: 57.508451
[Epoch 54] train=1.000000 val_top1=0.683300 val_top5=0.935700 loss=46031766.898438 time: 57.251366
[Epoch 55] train=1.000000 val_top1=0.700100 val_top5=0.936400 loss=46031298.601562 time: 56.914629
[Epoch 56] train=1.000000 val_top1=0.675200 val_top5=0.923700 loss=46030329.671875 time: 56.955461
[Epoch 57] train=1.000000 val_top1=0.695700 val_top5=0.935500 loss=46032949.046875 time: 56.779740
[Epoch 58] train=1.000000 val_top1=0.692200 val_top5=0.936900 loss=46031375.835938 time: 56.827079
[Epoch 59] train=1.000000 val_top1=0.702700 val_top5=0.934000 loss=46031018.664062 time: 56.958711
[Epoch 60] train=1.000000 val_top1=0.707000 val_top5=0.939100 loss=46029682.023438 time: 56.608015
[Epoch 61] train=1.000000 val_top1=0.702800 val_top5=0.935000 loss=46029627.367188 time: 56.358055
[Epoch 62] train=1.000000 val_top1=0.723200 val_top5=0.939700 loss=46031403.312500 time: 56.484314
[Epoch 63] train=1.000000 val_top1=0.709000 val_top5=0.937200 loss=46030321.320312 time: 55.870185
[Epoch 64] train=1.000000 val_top1=0.696900 val_top5=0.939100 loss=46030489.578125 time: 56.164792
[Epoch 65] train=1.000000 val_top1=0.698500 val_top5=0.935000 loss=46030565.664062 time: 56.346139
[Epoch 66] train=1.000000 val_top1=0.712400 val_top5=0.941900 loss=46030847.906250 time: 55.652490
[Epoch 67] train=1.000000 val_top1=0.709000 val_top5=0.940700 loss=46030358.281250 time: 56.400167
[Epoch 68] train=1.000000 val_top1=0.693300 val_top5=0.937000 loss=46030630.679688 time: 56.543622
[Epoch 69] train=1.000000 val_top1=0.708400 val_top5=0.936000 loss=46030020.609375 time: 57.304047
[Epoch 70] train=1.000000 val_top1=0.699600 val_top5=0.937700 loss=46029050.429688 time: 57.147251
[Epoch 71] train=1.000000 val_top1=0.707600 val_top5=0.939200 loss=46029375.148438 time: 57.021306
[Epoch 72] train=1.000000 val_top1=0.694100 val_top5=0.936500 loss=46030649.976562 time: 57.307328
[Epoch 73] train=1.000000 val_top1=0.726700 val_top5=0.945400 loss=46029692.117188 time: 56.979271
[Epoch 74] train=1.000000 val_top1=0.695000 val_top5=0.935300 loss=46028938.414062 time: 57.184199
[Epoch 75] train=1.000000 val_top1=0.717500 val_top5=0.943800 loss=46029348.101562 time: 56.713828
[Epoch 76] train=1.000000 val_top1=0.730200 val_top5=0.945600 loss=46031491.679688 time: 56.378514
[Epoch 77] train=1.000000 val_top1=0.705700 val_top5=0.936900 loss=46028820.765625 time: 55.811031
[Epoch 78] train=1.000000 val_top1=0.724900 val_top5=0.942900 loss=46028664.273438 time: 57.225763
[Epoch 79] train=1.000000 val_top1=0.712800 val_top5=0.940300 loss=46029947.093750 time: 57.921381
[Epoch 80] train=1.000000 val_top1=0.725900 val_top5=0.944100 loss=46029800.062500 time: 57.860157
[Epoch 81] train=1.000000 val_top1=0.723400 val_top5=0.941700 loss=46027763.859375 time: 58.244741
[Epoch 82] train=1.000000 val_top1=0.726700 val_top5=0.946900 loss=46028679.007812 time: 57.697038
[Epoch 83] train=1.000000 val_top1=0.714000 val_top5=0.941100 loss=46028886.882812 time: 58.235751
[Epoch 84] train=1.000000 val_top1=0.705600 val_top5=0.936000 loss=46028242.000000 time: 58.939791
[Epoch 85] train=1.000000 val_top1=0.730800 val_top5=0.944500 loss=46029417.734375 time: 57.921637
[Epoch 86] train=1.000000 val_top1=0.731200 val_top5=0.945700 loss=46028030.554688 time: 57.057632
[Epoch 87] train=1.000000 val_top1=0.715500 val_top5=0.946100 loss=46027443.367188 time: 56.115501
[Epoch 88] train=1.000000 val_top1=0.707600 val_top5=0.937800 loss=46027770.390625 time: 55.970149
[Epoch 89] train=1.000000 val_top1=0.737100 val_top5=0.946100 loss=46028639.937500 time: 56.429415
[Epoch 90] train=1.000000 val_top1=0.741100 val_top5=0.947700 loss=46029019.531250 time: 56.362247
[Epoch 91] train=1.000000 val_top1=0.733500 val_top5=0.943900 loss=46027319.664062 time: 56.461018
[Epoch 92] train=1.000000 val_top1=0.721800 val_top5=0.942500 loss=46028372.625000 time: 55.837984
[Epoch 93] train=1.000000 val_top1=0.740600 val_top5=0.947500 loss=46028011.828125 time: 56.575977
[Epoch 94] train=1.000000 val_top1=0.727100 val_top5=0.944000 loss=46027780.515625 time: 56.259662
[Epoch 95] train=1.000000 val_top1=0.732200 val_top5=0.946300 loss=46027510.351562 time: 56.057259
[Epoch 96] train=1.000000 val_top1=0.735100 val_top5=0.945800 loss=46027205.671875 time: 56.314550
[Epoch 97] train=1.000000 val_top1=0.726100 val_top5=0.946600 loss=46027797.781250 time: 56.420322
[Epoch 98] train=1.000000 val_top1=0.737600 val_top5=0.946000 loss=46026598.953125 time: 56.532147
[Epoch 99] train=1.000000 val_top1=0.728100 val_top5=0.943700 loss=46028527.359375 time: 56.503104
[Epoch 100] train=1.000000 val_top1=0.745000 val_top5=0.948900 loss=46027545.226562 time: 57.121156
[Epoch 101] train=1.000000 val_top1=0.745600 val_top5=0.951900 loss=46027823.054688 time: 56.101325
[Epoch 102] train=1.000000 val_top1=0.744900 val_top5=0.953000 loss=46027313.578125 time: 56.214350
[Epoch 103] train=1.000000 val_top1=0.735600 val_top5=0.945900 loss=46026329.523438 time: 55.615534
[Epoch 104] train=1.000000 val_top1=0.735900 val_top5=0.946800 loss=46027281.382812 time: 55.820824
[Epoch 105] train=1.000000 val_top1=0.738600 val_top5=0.948100 loss=46026634.164062 time: 55.697067
[Epoch 106] train=1.000000 val_top1=0.738000 val_top5=0.945200 loss=46027413.312500 time: 56.686682
[Epoch 107] train=1.000000 val_top1=0.742900 val_top5=0.946500 loss=46025207.953125 time: 56.153681
[Epoch 108] train=1.000000 val_top1=0.743100 val_top5=0.948000 loss=46026667.703125 time: 56.147842
[Epoch 109] train=1.000000 val_top1=0.723500 val_top5=0.938500 loss=46027636.546875 time: 55.796891
[Epoch 110] train=1.000000 val_top1=0.729200 val_top5=0.941000 loss=46025306.335938 time: 56.447251
[Epoch 111] train=1.000000 val_top1=0.737400 val_top5=0.945700 loss=46026510.757812 time: 56.470304
[Epoch 112] train=1.000000 val_top1=0.752300 val_top5=0.951700 loss=46026795.273438 time: 56.542035
[Epoch 113] train=1.000000 val_top1=0.742700 val_top5=0.948500 loss=46025875.226562 time: 56.148662
[Epoch 114] train=1.000000 val_top1=0.748600 val_top5=0.949500 loss=46024513.367188 time: 56.649859
[Epoch 115] train=1.000000 val_top1=0.736400 val_top5=0.947200 loss=46027613.210938 time: 56.783701
[Epoch 116] train=1.000000 val_top1=0.741500 val_top5=0.949100 loss=46026236.000000 time: 56.426527
[Epoch 117] train=1.000000 val_top1=0.756400 val_top5=0.954600 loss=46024838.562500 time: 55.448688
[Epoch 118] train=1.000000 val_top1=0.731400 val_top5=0.946700 loss=46024324.734375 time: 56.177514
[Epoch 119] train=1.000000 val_top1=0.748800 val_top5=0.942800 loss=46025312.562500 time: 56.469305
[Epoch 120] train=1.000000 val_top1=0.751000 val_top5=0.945300 loss=46024414.953125 time: 56.123001
[Epoch 121] train=1.000000 val_top1=0.752600 val_top5=0.952900 loss=46025450.742188 time: 56.162537
[Epoch 122] train=1.000000 val_top1=0.744100 val_top5=0.949400 loss=46025526.593750 time: 55.981962
[Epoch 123] train=1.000000 val_top1=0.746600 val_top5=0.947800 loss=46025413.156250 time: 56.367744
[Epoch 124] train=1.000000 val_top1=0.755400 val_top5=0.948600 loss=46024376.648438 time: 56.165816
[Epoch 125] train=1.000000 val_top1=0.756000 val_top5=0.951800 loss=46024160.531250 time: 55.968124
[Epoch 126] train=1.000000 val_top1=0.772900 val_top5=0.954900 loss=46024220.039062 time: 56.021730
[Epoch 127] train=1.000000 val_top1=0.762000 val_top5=0.946100 loss=46024097.757812 time: 56.692937
[Epoch 128] train=1.000000 val_top1=0.760700 val_top5=0.947000 loss=46025376.171875 time: 56.501720
[Epoch 129] train=1.000000 val_top1=0.760200 val_top5=0.950700 loss=46024534.117188 time: 56.441293
[Epoch 130] train=1.000000 val_top1=0.762600 val_top5=0.952900 loss=46023926.335938 time: 56.261219
[Epoch 131] train=1.000000 val_top1=0.759100 val_top5=0.949600 loss=46024512.726562 time: 55.739736
[Epoch 132] train=1.000000 val_top1=0.758500 val_top5=0.952700 loss=46023209.109375 time: 55.588304
[Epoch 133] train=1.000000 val_top1=0.753100 val_top5=0.947200 loss=46022254.273438 time: 56.565198
[Epoch 134] train=1.000000 val_top1=0.756800 val_top5=0.948000 loss=46023726.617188 time: 56.014259
[Epoch 135] train=1.000000 val_top1=0.765700 val_top5=0.955100 loss=46021484.312500 time: 56.283720
[Epoch 136] train=1.000000 val_top1=0.765500 val_top5=0.952700 loss=46023359.820312 time: 56.421469
[Epoch 137] train=1.000000 val_top1=0.764100 val_top5=0.955000 loss=46021618.671875 time: 55.828407
[Epoch 138] train=1.000000 val_top1=0.751300 val_top5=0.950100 loss=46023294.570312 time: 56.808623
[Epoch 139] train=1.000000 val_top1=0.771400 val_top5=0.955800 loss=46023121.421875 time: 56.506590
[Epoch 140] train=1.000000 val_top1=0.771400 val_top5=0.956000 loss=46024181.820312 time: 56.607303
[Epoch 141] train=1.000000 val_top1=0.771800 val_top5=0.955700 loss=46022339.664062 time: 56.207216
[Epoch 142] train=1.000000 val_top1=0.773500 val_top5=0.951200 loss=46021521.093750 time: 56.294322
[Epoch 143] train=1.000000 val_top1=0.753800 val_top5=0.949400 loss=46022013.742188 time: 56.746912
[Epoch 144] train=1.000000 val_top1=0.768500 val_top5=0.950400 loss=46021806.062500 time: 55.991296
[Epoch 145] train=1.000000 val_top1=0.771000 val_top5=0.952700 loss=46022213.039062 time: 56.283922
[Epoch 146] train=1.000000 val_top1=0.771200 val_top5=0.951300 loss=46022164.195312 time: 56.189984
[Epoch 147] train=1.000000 val_top1=0.776800 val_top5=0.954800 loss=46022306.007812 time: 57.726510
[Epoch 148] train=1.000000 val_top1=0.773200 val_top5=0.952600 loss=46021394.359375 time: 56.135884
[Epoch 149] train=1.000000 val_top1=0.779700 val_top5=0.953300 loss=46022567.218750 time: 55.967092
[Epoch 150] train=1.000000 val_top1=0.768700 val_top5=0.951200 loss=46020789.734375 time: 56.130442
[Epoch 151] train=1.000000 val_top1=0.776700 val_top5=0.952800 loss=46021313.242188 time: 55.761701
[Epoch 152] train=1.000000 val_top1=0.785100 val_top5=0.955800 loss=46021042.632812 time: 55.974854
[Epoch 153] train=1.000000 val_top1=0.770500 val_top5=0.951000 loss=46019177.515625 time: 55.779426
[Epoch 154] train=1.000000 val_top1=0.780900 val_top5=0.953500 loss=46021205.187500 time: 56.782180
[Epoch 155] train=1.000000 val_top1=0.773900 val_top5=0.954600 loss=46019918.625000 time: 55.983842
[Epoch 156] train=1.000000 val_top1=0.774400 val_top5=0.951100 loss=46021326.046875 time: 56.185675
[Epoch 157] train=1.000000 val_top1=0.780100 val_top5=0.954600 loss=46021092.578125 time: 56.680547
[Epoch 158] train=1.000000 val_top1=0.777400 val_top5=0.952000 loss=46019942.750000 time: 55.606858
[Epoch 159] train=1.000000 val_top1=0.783300 val_top5=0.956000 loss=46019749.726562 time: 56.731300
[Epoch 160] train=1.000000 val_top1=0.783300 val_top5=0.957400 loss=46019363.046875 time: 56.683726
[Epoch 161] train=1.000000 val_top1=0.782600 val_top5=0.952500 loss=46019463.101562 time: 56.664905
[Epoch 162] train=1.000000 val_top1=0.787500 val_top5=0.954300 loss=46020723.359375 time: 56.469231
[Epoch 163] train=1.000000 val_top1=0.791700 val_top5=0.954500 loss=46018158.164062 time: 56.703745
[Epoch 164] train=1.000000 val_top1=0.789900 val_top5=0.952700 loss=46018440.000000 time: 56.353384
[Epoch 165] train=1.000000 val_top1=0.788200 val_top5=0.954200 loss=46019290.554688 time: 55.873312
[Epoch 166] train=1.000000 val_top1=0.791600 val_top5=0.955500 loss=46019797.906250 time: 55.915579
[Epoch 167] train=1.000000 val_top1=0.791600 val_top5=0.954600 loss=46018045.906250 time: 56.183091
[Epoch 168] train=1.000000 val_top1=0.791300 val_top5=0.951700 loss=46019729.398438 time: 56.612638
[Epoch 169] train=1.000000 val_top1=0.791800 val_top5=0.955800 loss=46019874.429688 time: 56.208182
[Epoch 170] train=1.000000 val_top1=0.793800 val_top5=0.957300 loss=46019761.578125 time: 56.506516
[Epoch 171] train=1.000000 val_top1=0.789700 val_top5=0.954700 loss=46018686.875000 time: 55.830763
[Epoch 172] train=1.000000 val_top1=0.792500 val_top5=0.958200 loss=46018737.968750 time: 57.620954
[Epoch 173] train=1.000000 val_top1=0.794300 val_top5=0.958700 loss=46019061.187500 time: 55.449728
[Epoch 174] train=1.000000 val_top1=0.790300 val_top5=0.957200 loss=46017535.578125 time: 56.136874
[Epoch 175] train=1.000000 val_top1=0.791800 val_top5=0.955800 loss=46018985.132812 time: 56.546250
[Epoch 176] train=1.000000 val_top1=0.794700 val_top5=0.955500 loss=46016591.250000 time: 55.733364
[Epoch 177] train=1.000000 val_top1=0.794500 val_top5=0.956500 loss=46018762.601562 time: 56.298450
[Epoch 178] train=1.000000 val_top1=0.796200 val_top5=0.959500 loss=46019253.171875 time: 56.356905
[Epoch 179] train=1.000000 val_top1=0.793000 val_top5=0.955700 loss=46017582.906250 time: 56.390156
[Epoch 180] train=1.000000 val_top1=0.798600 val_top5=0.957200 loss=46018751.578125 time: 56.365007
[Epoch 181] train=1.000000 val_top1=0.793800 val_top5=0.957400 loss=46019671.960938 time: 56.150985
[Epoch 182] train=1.000000 val_top1=0.794100 val_top5=0.956000 loss=46017118.921875 time: 57.891326
[Epoch 183] train=1.000000 val_top1=0.797000 val_top5=0.955200 loss=46016804.992188 time: 56.413416
[Epoch 184] train=1.000000 val_top1=0.797200 val_top5=0.956000 loss=46018138.734375 time: 56.159120
[Epoch 185] train=1.000000 val_top1=0.799100 val_top5=0.954400 loss=46017927.578125 time: 55.923319
[Epoch 186] train=1.000000 val_top1=0.795900 val_top5=0.956000 loss=46017562.101562 time: 56.225650
[Epoch 187] train=1.000000 val_top1=0.796900 val_top5=0.957200 loss=46017607.710938 time: 56.864451
[Epoch 188] train=1.000000 val_top1=0.793100 val_top5=0.957400 loss=46018286.515625 time: 55.905194
[Epoch 189] train=1.000000 val_top1=0.796400 val_top5=0.957700 loss=46018213.867188 time: 58.261177
[Epoch 190] train=1.000000 val_top1=0.792900 val_top5=0.958000 loss=46018548.296875 time: 55.553876
[Epoch 191] train=1.000000 val_top1=0.798400 val_top5=0.956700 loss=46017990.476562 time: 56.707412
[Epoch 192] train=1.000000 val_top1=0.797700 val_top5=0.957000 loss=46018471.757812 time: 56.306646
[Epoch 193] train=1.000000 val_top1=0.793000 val_top5=0.957600 loss=46017243.609375 time: 56.871889
[Epoch 194] train=1.000000 val_top1=0.797400 val_top5=0.957500 loss=46016076.289062 time: 56.499064
[Epoch 195] train=1.000000 val_top1=0.795500 val_top5=0.957600 loss=46016565.890625 time: 56.160234
[Epoch 196] train=1.000000 val_top1=0.796800 val_top5=0.955200 loss=46017673.140625 time: 56.357360
[Epoch 197] train=1.000000 val_top1=0.796200 val_top5=0.957000 loss=46018355.234375 time: 56.717563
[Epoch 198] train=1.000000 val_top1=0.795100 val_top5=0.955100 loss=46017573.781250 time: 56.482913
[Epoch 199] train=1.000000 val_top1=0.797500 val_top5=0.957200 loss=46017818.757812 time: 56.782155
Done.
