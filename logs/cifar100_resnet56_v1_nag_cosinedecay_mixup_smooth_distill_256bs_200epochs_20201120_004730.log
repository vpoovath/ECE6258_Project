Imports successful

Using label smoothing: True
Using mixup: True

Model Init Done.
Dense(None -> 100, linear)

Teacher Model Init Done!
Preprocessing Step Successful.
Initialization of train_data and val_data successful.
Per Device Batch Size: 256
sparse label loss: False

Using label smoothing: True
Using mixup: True

Using nag Optimizer
{'lr_scheduler': <gluoncv.utils.lr_scheduler.LRSequential object at 0x7fbd1029b0d0>, 'wd': 0.0001, 'momentum': 0.9}

Number of warmup epochs: 20
Warmup Learning Rate Mode: linear
Learing Rate Mode: cosine
Learing Rate Decay: 0.1
Learning Rate Decay Epochs: [30, 60, 90, inf]

Training Settings Set Successfully.
Training loop started for 200 epochs:
[Epoch 0] train=1.000000 val_top1=0.090800 val_top5=0.349900 loss=46090019.250000 time: 103.701167
[Epoch 1] train=1.000000 val_top1=0.139400 val_top5=0.478700 loss=46073743.796875 time: 94.918090
[Epoch 2] train=1.000000 val_top1=0.182800 val_top5=0.537100 loss=46071351.500000 time: 96.750509
[Epoch 3] train=1.000000 val_top1=0.224200 val_top5=0.593200 loss=46069425.375000 time: 94.600823
[Epoch 4] train=1.000000 val_top1=0.266100 val_top5=0.652000 loss=46067139.921875 time: 94.451000
[Epoch 5] train=1.000000 val_top1=0.308900 val_top5=0.691600 loss=46064676.437500 time: 95.028608
[Epoch 6] train=1.000000 val_top1=0.311700 val_top5=0.701900 loss=46062359.796875 time: 94.504481
[Epoch 7] train=1.000000 val_top1=0.354800 val_top5=0.752300 loss=46059521.343750 time: 94.295722
[Epoch 8] train=1.000000 val_top1=0.400700 val_top5=0.786300 loss=46057512.765625 time: 94.412113
[Epoch 9] train=1.000000 val_top1=0.409400 val_top5=0.798200 loss=46055671.093750 time: 96.057414
[Epoch 10] train=1.000000 val_top1=0.364800 val_top5=0.770000 loss=46054121.312500 time: 94.968281
[Epoch 11] train=1.000000 val_top1=0.400300 val_top5=0.787100 loss=46051798.437500 time: 95.551162
[Epoch 12] train=1.000000 val_top1=0.475200 val_top5=0.835500 loss=46049684.000000 time: 96.493584
[Epoch 13] train=1.000000 val_top1=0.481800 val_top5=0.837600 loss=46049418.906250 time: 94.563600
[Epoch 14] train=1.000000 val_top1=0.502600 val_top5=0.855900 loss=46048996.015625 time: 95.031321
[Epoch 15] train=1.000000 val_top1=0.499300 val_top5=0.855900 loss=46046681.593750 time: 94.854273
[Epoch 16] train=1.000000 val_top1=0.512600 val_top5=0.836300 loss=46045914.250000 time: 94.680577
[Epoch 17] train=1.000000 val_top1=0.554700 val_top5=0.885400 loss=46045313.515625 time: 95.017352
[Epoch 18] train=1.000000 val_top1=0.517900 val_top5=0.847200 loss=46043341.359375 time: 94.323383
[Epoch 19] train=1.000000 val_top1=0.562100 val_top5=0.877100 loss=46041973.328125 time: 94.552743
[Epoch 20] train=1.000000 val_top1=0.508800 val_top5=0.849700 loss=46041469.765625 time: 95.245847
[Epoch 21] train=1.000000 val_top1=0.565000 val_top5=0.883300 loss=46041853.906250 time: 94.688499
[Epoch 22] train=1.000000 val_top1=0.591200 val_top5=0.894800 loss=46040292.406250 time: 95.520889
[Epoch 23] train=1.000000 val_top1=0.595700 val_top5=0.899300 loss=46039747.984375 time: 95.702041
[Epoch 24] train=1.000000 val_top1=0.599300 val_top5=0.904300 loss=46039775.000000 time: 96.794627
[Epoch 25] train=1.000000 val_top1=0.619900 val_top5=0.916600 loss=46038778.671875 time: 94.614363
[Epoch 26] train=1.000000 val_top1=0.633300 val_top5=0.914600 loss=46038452.453125 time: 94.467885
[Epoch 27] train=1.000000 val_top1=0.636300 val_top5=0.911500 loss=46039131.625000 time: 94.417118
[Epoch 28] train=1.000000 val_top1=0.641300 val_top5=0.919200 loss=46037272.968750 time: 94.489320
[Epoch 29] train=1.000000 val_top1=0.626300 val_top5=0.913400 loss=46037631.796875 time: 94.399333
[Epoch 30] train=1.000000 val_top1=0.621900 val_top5=0.908800 loss=46037131.046875 time: 94.748144
[Epoch 31] train=1.000000 val_top1=0.647800 val_top5=0.914500 loss=46036696.250000 time: 95.568368
[Epoch 32] train=1.000000 val_top1=0.663200 val_top5=0.926900 loss=46035668.484375 time: 94.995588
[Epoch 33] train=1.000000 val_top1=0.644900 val_top5=0.923400 loss=46036730.546875 time: 95.259995
[Epoch 34] train=1.000000 val_top1=0.674900 val_top5=0.930200 loss=46035176.937500 time: 95.604796
[Epoch 35] train=1.000000 val_top1=0.656000 val_top5=0.921700 loss=46034272.312500 time: 94.363336
[Epoch 36] train=1.000000 val_top1=0.672000 val_top5=0.928200 loss=46035953.953125 time: 94.861158
[Epoch 37] train=1.000000 val_top1=0.681200 val_top5=0.932300 loss=46034537.015625 time: 94.228220
[Epoch 38] train=1.000000 val_top1=0.667500 val_top5=0.927200 loss=46033845.359375 time: 95.242309
[Epoch 39] train=1.000000 val_top1=0.647000 val_top5=0.918400 loss=46033779.500000 time: 94.203869
[Epoch 40] train=1.000000 val_top1=0.631600 val_top5=0.911800 loss=46033720.312500 time: 94.282833
[Epoch 41] train=1.000000 val_top1=0.675000 val_top5=0.924400 loss=46033975.625000 time: 94.762123
[Epoch 42] train=1.000000 val_top1=0.642600 val_top5=0.917300 loss=46032742.531250 time: 94.190629
[Epoch 43] train=1.000000 val_top1=0.675900 val_top5=0.930800 loss=46032177.406250 time: 94.908627
[Epoch 44] train=1.000000 val_top1=0.689400 val_top5=0.934800 loss=46032574.625000 time: 94.245822
[Epoch 45] train=1.000000 val_top1=0.673100 val_top5=0.923500 loss=46032393.781250 time: 95.414967
[Epoch 46] train=1.000000 val_top1=0.664200 val_top5=0.925700 loss=46031453.125000 time: 94.696872
[Epoch 47] train=1.000000 val_top1=0.659500 val_top5=0.917400 loss=46031752.343750 time: 95.179532
[Epoch 48] train=1.000000 val_top1=0.665600 val_top5=0.922000 loss=46033083.265625 time: 94.837843
[Epoch 49] train=1.000000 val_top1=0.678300 val_top5=0.928500 loss=46030348.140625 time: 95.810315
[Epoch 50] train=1.000000 val_top1=0.666400 val_top5=0.918500 loss=46029772.171875 time: 95.263265
[Epoch 51] train=1.000000 val_top1=0.688700 val_top5=0.932000 loss=46030777.093750 time: 94.748116
[Epoch 52] train=1.000000 val_top1=0.713800 val_top5=0.942800 loss=46031530.140625 time: 94.251083
[Epoch 53] train=1.000000 val_top1=0.676900 val_top5=0.926900 loss=46032027.296875 time: 94.521637
[Epoch 54] train=1.000000 val_top1=0.683200 val_top5=0.934500 loss=46031896.218750 time: 94.373219
[Epoch 55] train=1.000000 val_top1=0.675400 val_top5=0.924300 loss=46032213.812500 time: 94.313356
[Epoch 56] train=1.000000 val_top1=0.699200 val_top5=0.930900 loss=46030898.859375 time: 95.000746
[Epoch 57] train=1.000000 val_top1=0.684600 val_top5=0.922200 loss=46031291.312500 time: 95.672338
[Epoch 58] train=1.000000 val_top1=0.652900 val_top5=0.916600 loss=46029879.406250 time: 95.037145
[Epoch 59] train=1.000000 val_top1=0.710100 val_top5=0.937200 loss=46030655.156250 time: 94.747038
[Epoch 60] train=1.000000 val_top1=0.701100 val_top5=0.938600 loss=46029734.015625 time: 97.469652
[Epoch 61] train=1.000000 val_top1=0.684000 val_top5=0.924300 loss=46032761.359375 time: 94.225263
[Epoch 62] train=1.000000 val_top1=0.686200 val_top5=0.928500 loss=46028531.515625 time: 94.441839
[Epoch 63] train=1.000000 val_top1=0.707200 val_top5=0.930100 loss=46029899.718750 time: 94.285868
[Epoch 64] train=1.000000 val_top1=0.698100 val_top5=0.932900 loss=46028569.484375 time: 94.417797
[Epoch 65] train=1.000000 val_top1=0.694100 val_top5=0.929200 loss=46030850.421875 time: 95.063427
[Epoch 66] train=1.000000 val_top1=0.682100 val_top5=0.918300 loss=46030498.015625 time: 95.389002
[Epoch 67] train=1.000000 val_top1=0.701600 val_top5=0.933800 loss=46030005.187500 time: 96.625149
[Epoch 68] train=1.000000 val_top1=0.714800 val_top5=0.936100 loss=46026961.468750 time: 95.044590
[Epoch 69] train=1.000000 val_top1=0.684100 val_top5=0.931400 loss=46028736.750000 time: 94.863746
[Epoch 70] train=1.000000 val_top1=0.712900 val_top5=0.935800 loss=46030090.531250 time: 95.762339
[Epoch 71] train=1.000000 val_top1=0.684900 val_top5=0.932500 loss=46029689.859375 time: 95.277989
[Epoch 72] train=1.000000 val_top1=0.717300 val_top5=0.935800 loss=46030550.296875 time: 95.858938
[Epoch 73] train=1.000000 val_top1=0.724600 val_top5=0.941300 loss=46027895.453125 time: 95.219662
[Epoch 74] train=1.000000 val_top1=0.718300 val_top5=0.937300 loss=46026788.390625 time: 94.810846
[Epoch 75] train=1.000000 val_top1=0.688400 val_top5=0.936400 loss=46028824.187500 time: 95.265059
[Epoch 76] train=1.000000 val_top1=0.707700 val_top5=0.937800 loss=46028992.390625 time: 94.866718
[Epoch 77] train=1.000000 val_top1=0.693500 val_top5=0.928100 loss=46027540.750000 time: 96.196429
[Epoch 78] train=1.000000 val_top1=0.689100 val_top5=0.935400 loss=46029384.312500 time: 95.785740
[Epoch 79] train=1.000000 val_top1=0.693600 val_top5=0.937700 loss=46027261.937500 time: 96.486618
[Epoch 80] train=1.000000 val_top1=0.714400 val_top5=0.938900 loss=46028404.843750 time: 97.788238
[Epoch 81] train=1.000000 val_top1=0.722100 val_top5=0.941700 loss=46027194.859375 time: 95.461069
[Epoch 82] train=1.000000 val_top1=0.696900 val_top5=0.929600 loss=46027866.937500 time: 96.989487
[Epoch 83] train=1.000000 val_top1=0.715500 val_top5=0.927800 loss=46027154.406250 time: 95.725390
[Epoch 84] train=1.000000 val_top1=0.712400 val_top5=0.939500 loss=46028478.703125 time: 96.351093
[Epoch 85] train=1.000000 val_top1=0.719400 val_top5=0.940100 loss=46026956.156250 time: 96.332855
[Epoch 86] train=1.000000 val_top1=0.733100 val_top5=0.942400 loss=46027447.859375 time: 95.730031
[Epoch 87] train=1.000000 val_top1=0.722000 val_top5=0.946000 loss=46026882.375000 time: 97.312533
[Epoch 88] train=1.000000 val_top1=0.721700 val_top5=0.935700 loss=46026615.296875 time: 95.953113
[Epoch 89] train=1.000000 val_top1=0.710100 val_top5=0.936100 loss=46026479.875000 time: 97.693394
[Epoch 90] train=1.000000 val_top1=0.736400 val_top5=0.944900 loss=46025961.890625 time: 97.486653
[Epoch 91] train=1.000000 val_top1=0.693700 val_top5=0.926000 loss=46027889.796875 time: 97.484612
[Epoch 92] train=1.000000 val_top1=0.725500 val_top5=0.944300 loss=46025128.375000 time: 95.894501
[Epoch 93] train=1.000000 val_top1=0.735000 val_top5=0.944200 loss=46027992.609375 time: 96.166925
[Epoch 94] train=1.000000 val_top1=0.740700 val_top5=0.945900 loss=46026146.250000 time: 96.857300
[Epoch 95] train=1.000000 val_top1=0.725600 val_top5=0.936700 loss=46026914.187500 time: 96.442456
[Epoch 96] train=1.000000 val_top1=0.709600 val_top5=0.932700 loss=46024427.593750 time: 96.767675
[Epoch 97] train=1.000000 val_top1=0.728300 val_top5=0.940100 loss=46026889.625000 time: 96.715234
[Epoch 98] train=1.000000 val_top1=0.715600 val_top5=0.940000 loss=46028145.500000 time: 96.801304
[Epoch 99] train=1.000000 val_top1=0.741600 val_top5=0.945400 loss=46027197.359375 time: 95.861161
[Epoch 100] train=1.000000 val_top1=0.726600 val_top5=0.939800 loss=46025772.953125 time: 97.926666
[Epoch 101] train=1.000000 val_top1=0.713100 val_top5=0.930100 loss=46027441.500000 time: 95.894358
[Epoch 102] train=1.000000 val_top1=0.734800 val_top5=0.943700 loss=46027748.937500 time: 95.566645
[Epoch 103] train=1.000000 val_top1=0.719200 val_top5=0.938200 loss=46024381.671875 time: 95.384757
[Epoch 104] train=1.000000 val_top1=0.732500 val_top5=0.942900 loss=46025692.187500 time: 96.708769
[Epoch 105] train=1.000000 val_top1=0.727000 val_top5=0.939600 loss=46025702.953125 time: 97.191463
[Epoch 106] train=1.000000 val_top1=0.726900 val_top5=0.936100 loss=46025233.687500 time: 99.293294
[Epoch 107] train=1.000000 val_top1=0.746000 val_top5=0.947700 loss=46026182.640625 time: 96.227837
[Epoch 108] train=1.000000 val_top1=0.716300 val_top5=0.935100 loss=46024967.203125 time: 96.462340
[Epoch 109] train=1.000000 val_top1=0.739700 val_top5=0.942400 loss=46025401.578125 time: 96.423861
[Epoch 110] train=1.000000 val_top1=0.740200 val_top5=0.943500 loss=46025034.750000 time: 98.610803
[Epoch 111] train=1.000000 val_top1=0.738500 val_top5=0.937100 loss=46022509.531250 time: 96.654646
[Epoch 112] train=1.000000 val_top1=0.736600 val_top5=0.944300 loss=46025032.156250 time: 97.093869
[Epoch 113] train=1.000000 val_top1=0.740100 val_top5=0.948600 loss=46026426.812500 time: 96.457742
[Epoch 114] train=1.000000 val_top1=0.742500 val_top5=0.945700 loss=46024759.140625 time: 96.568928
[Epoch 115] train=1.000000 val_top1=0.756600 val_top5=0.945700 loss=46024424.234375 time: 96.754754
[Epoch 116] train=1.000000 val_top1=0.729000 val_top5=0.936100 loss=46023597.250000 time: 95.871683
[Epoch 117] train=1.000000 val_top1=0.751800 val_top5=0.949100 loss=46020324.531250 time: 95.602045
[Epoch 118] train=1.000000 val_top1=0.744400 val_top5=0.942500 loss=46024032.171875 time: 96.642677
[Epoch 119] train=1.000000 val_top1=0.747700 val_top5=0.939300 loss=46021842.578125 time: 95.789903
[Epoch 120] train=1.000000 val_top1=0.722300 val_top5=0.935400 loss=46025421.687500 time: 97.260910
[Epoch 121] train=1.000000 val_top1=0.743500 val_top5=0.945200 loss=46023057.921875 time: 95.765032
[Epoch 122] train=1.000000 val_top1=0.736400 val_top5=0.938900 loss=46022332.828125 time: 95.903002
[Epoch 123] train=1.000000 val_top1=0.731200 val_top5=0.938700 loss=46023552.125000 time: 96.278104
[Epoch 124] train=1.000000 val_top1=0.751000 val_top5=0.946000 loss=46024031.843750 time: 95.307583
[Epoch 125] train=1.000000 val_top1=0.743500 val_top5=0.939600 loss=46022577.343750 time: 95.149057
[Epoch 126] train=1.000000 val_top1=0.755800 val_top5=0.944500 loss=46023068.343750 time: 96.313803
[Epoch 127] train=1.000000 val_top1=0.750500 val_top5=0.941800 loss=46021994.031250 time: 95.651024
[Epoch 128] train=1.000000 val_top1=0.747700 val_top5=0.944300 loss=46021028.250000 time: 94.726530
[Epoch 129] train=1.000000 val_top1=0.748200 val_top5=0.944900 loss=46022280.953125 time: 94.602397
[Epoch 130] train=1.000000 val_top1=0.751200 val_top5=0.943100 loss=46021969.421875 time: 95.136991
[Epoch 131] train=1.000000 val_top1=0.752500 val_top5=0.948700 loss=46021424.828125 time: 94.593910
[Epoch 132] train=1.000000 val_top1=0.743300 val_top5=0.943000 loss=46022510.593750 time: 95.205781
[Epoch 133] train=1.000000 val_top1=0.740800 val_top5=0.936800 loss=46021335.296875 time: 96.291796
[Epoch 134] train=1.000000 val_top1=0.749600 val_top5=0.943100 loss=46024658.859375 time: 95.071225
[Epoch 135] train=1.000000 val_top1=0.754700 val_top5=0.946400 loss=46020673.265625 time: 95.079533
[Epoch 136] train=1.000000 val_top1=0.755600 val_top5=0.948100 loss=46021209.890625 time: 94.513434
[Epoch 137] train=1.000000 val_top1=0.765900 val_top5=0.943400 loss=46022337.906250 time: 95.257771
[Epoch 138] train=1.000000 val_top1=0.755000 val_top5=0.946200 loss=46021196.390625 time: 94.913415
[Epoch 139] train=1.000000 val_top1=0.761200 val_top5=0.949700 loss=46021528.546875 time: 94.787854
[Epoch 140] train=1.000000 val_top1=0.757700 val_top5=0.943500 loss=46019592.296875 time: 94.600454
[Epoch 141] train=1.000000 val_top1=0.767100 val_top5=0.949900 loss=46020243.578125 time: 94.525195
[Epoch 142] train=1.000000 val_top1=0.756300 val_top5=0.943100 loss=46020764.437500 time: 94.586238
[Epoch 143] train=1.000000 val_top1=0.753100 val_top5=0.942000 loss=46021361.843750 time: 95.618024
[Epoch 144] train=1.000000 val_top1=0.747600 val_top5=0.940000 loss=46020578.500000 time: 95.311656
[Epoch 145] train=1.000000 val_top1=0.761400 val_top5=0.945000 loss=46022639.312500 time: 94.633707
[Epoch 146] train=1.000000 val_top1=0.759500 val_top5=0.947600 loss=46021933.984375 time: 94.458271
[Epoch 147] train=1.000000 val_top1=0.757200 val_top5=0.946800 loss=46021031.125000 time: 95.440306
[Epoch 148] train=1.000000 val_top1=0.760500 val_top5=0.943200 loss=46018215.046875 time: 94.829789
[Epoch 149] train=1.000000 val_top1=0.767200 val_top5=0.946100 loss=46019938.234375 time: 94.568115
[Epoch 150] train=1.000000 val_top1=0.760200 val_top5=0.945500 loss=46020334.156250 time: 94.671037
[Epoch 151] train=1.000000 val_top1=0.766000 val_top5=0.946400 loss=46021378.625000 time: 94.647889
[Epoch 152] train=1.000000 val_top1=0.773700 val_top5=0.948900 loss=46019134.687500 time: 96.654005
[Epoch 153] train=1.000000 val_top1=0.765600 val_top5=0.949200 loss=46020102.875000 time: 94.720119
[Epoch 154] train=1.000000 val_top1=0.774100 val_top5=0.949800 loss=46023261.093750 time: 95.363219
[Epoch 155] train=1.000000 val_top1=0.769900 val_top5=0.944700 loss=46019342.078125 time: 95.621264
[Epoch 156] train=1.000000 val_top1=0.765000 val_top5=0.943500 loss=46020365.812500 time: 94.791217
[Epoch 157] train=1.000000 val_top1=0.767800 val_top5=0.948200 loss=46019561.046875 time: 95.411697
[Epoch 158] train=1.000000 val_top1=0.758900 val_top5=0.946100 loss=46017807.578125 time: 94.627777
[Epoch 159] train=1.000000 val_top1=0.771800 val_top5=0.947300 loss=46017448.593750 time: 94.791546
[Epoch 160] train=1.000000 val_top1=0.777300 val_top5=0.952200 loss=46019670.968750 time: 94.653996
[Epoch 161] train=1.000000 val_top1=0.778900 val_top5=0.947900 loss=46018604.671875 time: 95.226945
[Epoch 162] train=1.000000 val_top1=0.766600 val_top5=0.946400 loss=46018670.265625 time: 95.827280
[Epoch 163] train=1.000000 val_top1=0.772700 val_top5=0.949300 loss=46017102.765625 time: 95.790133
[Epoch 164] train=1.000000 val_top1=0.777600 val_top5=0.951200 loss=46019569.640625 time: 94.603185
[Epoch 165] train=1.000000 val_top1=0.776800 val_top5=0.948800 loss=46016457.156250 time: 97.409708
[Epoch 166] train=1.000000 val_top1=0.774000 val_top5=0.945900 loss=46018991.375000 time: 95.951694
[Epoch 167] train=1.000000 val_top1=0.776300 val_top5=0.950100 loss=46018869.562500 time: 94.808453
[Epoch 168] train=1.000000 val_top1=0.778700 val_top5=0.947800 loss=46021191.453125 time: 94.637227
[Epoch 169] train=1.000000 val_top1=0.774100 val_top5=0.948100 loss=46018000.828125 time: 94.620957
[Epoch 170] train=1.000000 val_top1=0.774000 val_top5=0.948500 loss=46019028.859375 time: 95.117602
[Epoch 171] train=1.000000 val_top1=0.783000 val_top5=0.944700 loss=46017932.984375 time: 95.090144
[Epoch 172] train=1.000000 val_top1=0.779900 val_top5=0.950500 loss=46020617.531250 time: 95.399748
[Epoch 173] train=1.000000 val_top1=0.780800 val_top5=0.949800 loss=46020837.421875 time: 94.684585
[Epoch 174] train=1.000000 val_top1=0.783800 val_top5=0.949800 loss=46017529.562500 time: 94.629850
[Epoch 175] train=1.000000 val_top1=0.780700 val_top5=0.949100 loss=46017863.812500 time: 96.428889
[Epoch 176] train=1.000000 val_top1=0.782000 val_top5=0.949800 loss=46016350.906250 time: 97.515445
[Epoch 177] train=1.000000 val_top1=0.779200 val_top5=0.948400 loss=46019313.156250 time: 95.943711
[Epoch 178] train=1.000000 val_top1=0.781500 val_top5=0.950100 loss=46019359.828125 time: 94.951437
[Epoch 179] train=1.000000 val_top1=0.782300 val_top5=0.950500 loss=46016043.078125 time: 95.122112
[Epoch 180] train=1.000000 val_top1=0.779300 val_top5=0.949400 loss=46017153.359375 time: 94.459807
[Epoch 181] train=1.000000 val_top1=0.782100 val_top5=0.950100 loss=46016768.812500 time: 95.999620
[Epoch 182] train=1.000000 val_top1=0.783600 val_top5=0.949200 loss=46017445.843750 time: 95.273622
[Epoch 183] train=1.000000 val_top1=0.781000 val_top5=0.951000 loss=46018426.359375 time: 94.323565
[Epoch 184] train=1.000000 val_top1=0.783400 val_top5=0.949700 loss=46020822.531250 time: 94.608249
[Epoch 185] train=1.000000 val_top1=0.783300 val_top5=0.950400 loss=46019736.171875 time: 95.340652
[Epoch 186] train=1.000000 val_top1=0.780200 val_top5=0.951800 loss=46016888.843750 time: 94.813833
[Epoch 187] train=1.000000 val_top1=0.781000 val_top5=0.949300 loss=46018406.906250 time: 94.280992
[Epoch 188] train=1.000000 val_top1=0.781200 val_top5=0.950100 loss=46018083.890625 time: 94.713218
[Epoch 189] train=1.000000 val_top1=0.784100 val_top5=0.949800 loss=46017915.812500 time: 95.884411
[Epoch 190] train=1.000000 val_top1=0.779900 val_top5=0.949100 loss=46018909.125000 time: 94.871038
[Epoch 191] train=1.000000 val_top1=0.783700 val_top5=0.949700 loss=46020371.125000 time: 95.720941
[Epoch 192] train=1.000000 val_top1=0.783200 val_top5=0.950700 loss=46014234.796875 time: 95.496832
[Epoch 193] train=1.000000 val_top1=0.782900 val_top5=0.950900 loss=46017436.234375 time: 95.819693
[Epoch 194] train=1.000000 val_top1=0.785800 val_top5=0.949500 loss=46016377.937500 time: 94.707109
[Epoch 195] train=1.000000 val_top1=0.781300 val_top5=0.949500 loss=46018902.906250 time: 95.396947
[Epoch 196] train=1.000000 val_top1=0.783600 val_top5=0.949400 loss=46017870.562500 time: 95.025666
[Epoch 197] train=1.000000 val_top1=0.780500 val_top5=0.949600 loss=46020238.781250 time: 94.407318
[Epoch 198] train=1.000000 val_top1=0.784300 val_top5=0.950100 loss=46017073.281250 time: 94.323117
[Epoch 199] train=1.000000 val_top1=0.784900 val_top5=0.950000 loss=46016588.906250 time: 96.113621
Done.
