Imports successful
Model Init Done.
Preprocessing Step Successful.
Initialization of train_data and val_data successful.
Training loop started:
[Epoch 0] train=0.108574 val=0.161600 loss=146557.161224 time: 31.037323
[Epoch 1] train=0.196835 val=0.243200 loss=130148.765991 time: 31.258713
[Epoch 2] train=0.250461 val=0.285000 loss=120520.802094 time: 31.325749
[Epoch 3] train=0.302704 val=0.314500 loss=112281.521545 time: 31.135185
[Epoch 4] train=0.341847 val=0.361500 loss=105405.192520 time: 31.268888
[Epoch 5] train=0.389183 val=0.406400 loss=97897.691162 time: 31.063687
[Epoch 6] train=0.424058 val=0.433100 loss=91910.166306 time: 31.263761
[Epoch 7] train=0.447095 val=0.464400 loss=87944.881180 time: 31.003613
[Epoch 8] train=0.473317 val=0.468900 loss=83480.087540 time: 31.344577
[Epoch 9] train=0.476843 val=0.454700 loss=83175.594925 time: 31.417068
[Epoch 10] train=0.505909 val=0.502800 loss=78576.806259 time: 31.231318
[Epoch 11] train=0.524659 val=0.515200 loss=75688.898331 time: 31.376189
[Epoch 12] train=0.535597 val=0.513300 loss=73381.197098 time: 31.229640
[Epoch 13] train=0.553666 val=0.540700 loss=70449.839340 time: 31.079851
[Epoch 14] train=0.567388 val=0.552000 loss=68634.707108 time: 30.880478
[Epoch 15] train=0.578926 val=0.552100 loss=66463.733704 time: 30.986273
[Epoch 16] train=0.590545 val=0.564700 loss=64442.247765 time: 31.268350
[Epoch 17] train=0.599379 val=0.580700 loss=62878.276550 time: 30.913435
[Epoch 18] train=0.612480 val=0.514600 loss=61370.482742 time: 31.086530
[Epoch 19] train=0.616767 val=0.569900 loss=60110.026222 time: 31.176126
[Epoch 20] train=0.627524 val=0.601000 loss=58440.112183 time: 31.211861
[Epoch 21] train=0.637520 val=0.564100 loss=57035.579735 time: 31.261402
[Epoch 22] train=0.641867 val=0.581600 loss=56061.375084 time: 31.264663
[Epoch 23] train=0.646454 val=0.591900 loss=55125.971336 time: 31.158338
[Epoch 24] train=0.650761 val=0.605200 loss=54403.055183 time: 31.326586
[Epoch 25] train=0.660437 val=0.612000 loss=53216.524208 time: 31.067101
[Epoch 26] train=0.668329 val=0.618400 loss=51888.407562 time: 31.181115
[Epoch 27] train=0.670292 val=0.581200 loss=51359.248459 time: 31.182659
[Epoch 28] train=0.677183 val=0.621800 loss=50434.150253 time: 31.000738
[Epoch 29] train=0.679387 val=0.632500 loss=49913.506912 time: 31.055317
[Epoch 30] train=0.737179 val=0.697400 loss=40941.955002 time: 30.840928
[Epoch 31] train=0.765905 val=0.702900 loss=36251.577553 time: 31.360677
[Epoch 32] train=0.774659 val=0.707800 loss=34740.530106 time: 30.950626
[Epoch 33] train=0.781390 val=0.708900 loss=33567.805454 time: 31.024648
[Epoch 34] train=0.787600 val=0.709700 loss=32731.655209 time: 30.784768
[Epoch 35] train=0.792087 val=0.713700 loss=32148.559856 time: 31.137335
[Epoch 36] train=0.796214 val=0.709300 loss=31150.853367 time: 30.746116
[Epoch 37] train=0.799459 val=0.711800 loss=30555.178436 time: 30.960614
[Epoch 38] train=0.801382 val=0.715000 loss=30403.735920 time: 30.872977
[Epoch 39] train=0.807933 val=0.708600 loss=29573.026726 time: 30.879913
[Epoch 40] train=0.809756 val=0.709200 loss=29046.814281 time: 31.179120
[Epoch 41] train=0.812961 val=0.708900 loss=28544.305630 time: 31.371601
[Epoch 42] train=0.816246 val=0.708400 loss=28144.508366 time: 31.264686
[Epoch 43] train=0.816526 val=0.711600 loss=27869.958374 time: 31.368268
[Epoch 44] train=0.820533 val=0.706900 loss=27357.858028 time: 31.085672
[Epoch 45] train=0.823337 val=0.708900 loss=26951.137127 time: 31.058091
[Epoch 46] train=0.827083 val=0.716300 loss=26380.968304 time: 30.823514
[Epoch 47] train=0.827744 val=0.711700 loss=25921.877132 time: 30.888108
[Epoch 48] train=0.829688 val=0.711500 loss=25870.819893 time: 30.977145
[Epoch 49] train=0.829046 val=0.710600 loss=25586.679333 time: 30.905217
[Epoch 50] train=0.836078 val=0.706900 loss=25052.299213 time: 30.833437
[Epoch 51] train=0.837300 val=0.711000 loss=24701.171776 time: 30.873502
[Epoch 52] train=0.838522 val=0.716600 loss=24212.185852 time: 31.059782
[Epoch 53] train=0.841446 val=0.720100 loss=23982.549896 time: 30.984035
[Epoch 54] train=0.845813 val=0.709200 loss=23468.437328 time: 30.978591
[Epoch 55] train=0.846554 val=0.706400 loss=23300.737333 time: 30.821625
[Epoch 56] train=0.847536 val=0.717400 loss=23101.009216 time: 31.125947
[Epoch 57] train=0.851643 val=0.714800 loss=22531.368660 time: 30.769890
[Epoch 58] train=0.853225 val=0.711100 loss=22237.854916 time: 31.078264
[Epoch 59] train=0.854788 val=0.711600 loss=21989.226446 time: 30.770231
[Epoch 60] train=0.867228 val=0.720200 loss=19955.781816 time: 31.076817
[Epoch 61] train=0.875260 val=0.722700 loss=18875.016281 time: 30.886821
[Epoch 62] train=0.878305 val=0.724300 loss=18503.173763 time: 30.971219
[Epoch 63] train=0.880128 val=0.723400 loss=18236.800079 time: 30.868536
[Epoch 64] train=0.878486 val=0.722600 loss=18415.568483 time: 30.873352
[Epoch 65] train=0.882953 val=0.722700 loss=18025.442986 time: 31.021618
[Epoch 66] train=0.882412 val=0.723400 loss=17951.708609 time: 31.154170
[Epoch 67] train=0.884675 val=0.721100 loss=17777.399561 time: 30.800240
[Epoch 68] train=0.886218 val=0.722200 loss=17376.982967 time: 30.944470
[Epoch 69] train=0.884555 val=0.722900 loss=17502.236998 time: 31.030115
[Epoch 70] train=0.884716 val=0.722400 loss=17612.686672 time: 31.224568
[Epoch 71] train=0.885978 val=0.722600 loss=17589.667402 time: 31.007633
[Epoch 72] train=0.891106 val=0.723100 loss=16956.527979 time: 30.699017
[Epoch 73] train=0.886819 val=0.722100 loss=17220.546568 time: 30.969249
[Epoch 74] train=0.889303 val=0.721700 loss=16916.903177 time: 31.136135
[Epoch 75] train=0.889163 val=0.722400 loss=16838.467499 time: 31.143092
[Epoch 76] train=0.889343 val=0.721400 loss=16937.415550 time: 31.182421
[Epoch 77] train=0.889283 val=0.722300 loss=16820.914598 time: 31.277875
[Epoch 78] train=0.890064 val=0.722300 loss=16805.366266 time: 30.943587
[Epoch 79] train=0.891246 val=0.721800 loss=16740.871302 time: 31.069169
[Epoch 80] train=0.893490 val=0.720100 loss=16351.040571 time: 31.142947
[Epoch 81] train=0.893630 val=0.720200 loss=16248.199934 time: 31.300199
[Epoch 82] train=0.892508 val=0.719900 loss=16345.279106 time: 31.115297
[Epoch 83] train=0.894030 val=0.719900 loss=16082.565872 time: 30.961240
[Epoch 84] train=0.892107 val=0.720000 loss=16482.715431 time: 30.885949
[Epoch 85] train=0.894732 val=0.721600 loss=16027.393553 time: 31.089219
[Epoch 86] train=0.893209 val=0.720000 loss=16075.644129 time: 30.958616
[Epoch 87] train=0.893870 val=0.721300 loss=16126.825584 time: 30.873211
[Epoch 88] train=0.895032 val=0.720400 loss=15971.352331 time: 30.896883
[Epoch 89] train=0.893570 val=0.720700 loss=16086.118519 time: 30.751032
[Epoch 90] train=0.897536 val=0.719100 loss=15675.872120 time: 31.236905
[Epoch 91] train=0.899439 val=0.721100 loss=15333.115713 time: 31.231054
[Epoch 92] train=0.898257 val=0.720000 loss=15563.413914 time: 31.051001
[Epoch 93] train=0.896975 val=0.720100 loss=15785.519569 time: 31.086954
[Epoch 94] train=0.899740 val=0.718800 loss=15387.124380 time: 31.328293
[Epoch 95] train=0.897937 val=0.721300 loss=15485.799570 time: 30.778903
[Epoch 96] train=0.897035 val=0.719200 loss=15704.761339 time: 31.065505
[Epoch 97] train=0.900641 val=0.721400 loss=15392.468964 time: 31.240515
[Epoch 98] train=0.898397 val=0.719600 loss=15492.910151 time: 31.055701
[Epoch 99] train=0.898558 val=0.722400 loss=15476.239857 time: 31.354634
[Epoch 100] train=0.897796 val=0.721900 loss=15545.128574 time: 31.169412
[Epoch 101] train=0.898718 val=0.719600 loss=15617.412092 time: 30.970761
[Epoch 102] train=0.899399 val=0.720200 loss=15547.926960 time: 31.135494
[Epoch 103] train=0.898958 val=0.719700 loss=15503.127705 time: 31.044020
[Epoch 104] train=0.900741 val=0.721800 loss=15195.468128 time: 31.151685
[Epoch 105] train=0.898097 val=0.721000 loss=15622.360353 time: 31.231176
[Epoch 106] train=0.897857 val=0.718800 loss=15503.500895 time: 31.260390
[Epoch 107] train=0.899399 val=0.720800 loss=15221.029839 time: 30.889013
[Epoch 108] train=0.899379 val=0.719200 loss=15446.692581 time: 31.142638
[Epoch 109] train=0.899499 val=0.721000 loss=15343.266201 time: 31.365728
[Epoch 110] train=0.899259 val=0.720700 loss=15251.887072 time: 31.194462
[Epoch 111] train=0.901983 val=0.722100 loss=15222.655809 time: 31.482975
[Epoch 112] train=0.900461 val=0.722000 loss=15318.794012 time: 31.262183
[Epoch 113] train=0.898938 val=0.720700 loss=15379.592243 time: 31.295948
[Epoch 114] train=0.898057 val=0.720600 loss=15453.435921 time: 31.240840
[Epoch 115] train=0.899199 val=0.720400 loss=15429.168503 time: 31.438353
[Epoch 116] train=0.898998 val=0.721200 loss=15379.963852 time: 31.039608
[Epoch 117] train=0.900421 val=0.720600 loss=15288.343534 time: 31.162312
[Epoch 118] train=0.900000 val=0.721400 loss=15259.639185 time: 31.118421
[Epoch 119] train=0.898518 val=0.720100 loss=15458.924780 time: 31.379122
Done.
