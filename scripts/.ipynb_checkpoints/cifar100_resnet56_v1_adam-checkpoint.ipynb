{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import argparse, time, logging, random, math\n",
    "\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "from mxnet import gluon, nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.utils import makedirs, TrainingHistory\n",
    "from gluoncv.data import transforms as gcv_transforms\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Init Done.\n"
     ]
    }
   ],
   "source": [
    "# number of GPUs to use\n",
    "num_gpus = 1\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "\n",
    "net = get_model('cifar_resnet56_v1', classes=100)\n",
    "net.initialize(mx.init.Xavier(), ctx = ctx)\n",
    "print(\"Model Init Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Step Successful.\n"
     ]
    }
   ],
   "source": [
    "resize = 32\n",
    "mean_rgb = [0.485, 0.456, 0.406]\n",
    "std_rgb = [0.229, 0.224, 0.225]\n",
    "max_aspect_ratio = 4.0 / 3.0\n",
    "min_aspect_ratio = 3.0 / 4.0\n",
    "max_random_area = 1\n",
    "min_random_area = 0.08\n",
    "jitter_param = 0.4\n",
    "lighting_param = 0.1\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "#     transforms.RandomResizedCrop(resize,\n",
    "#                                  scale=(min_random_area, max_random_area), \n",
    "#                                  ratio=(min_aspect_ratio, max_aspect_ratio)),\n",
    "    \n",
    "        # Randomly flip the image horizontally\n",
    "    transforms.RandomFlipLeftRight(),\n",
    "    \n",
    "    transforms.RandomBrightness(brightness=jitter_param),\n",
    "    transforms.RandomSaturation(saturation=jitter_param),\n",
    "    transforms.RandomHue(hue=jitter_param),\n",
    "    \n",
    "    transforms.RandomLighting(lighting_param),\n",
    "    \n",
    "    # Randomly crop an area and resize it to be 32x32, then pad it to be 40x40\n",
    "    gcv_transforms.RandomCrop(32, pad=4),\n",
    "        \n",
    "    # Transpose the image from height*width*num_channels to num_channels*height*width\n",
    "    # and map values from [0, 255] to [0,1]\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # Normalize the image with mean and standard deviation calculated across all images\n",
    "    transforms.Normalize(mean_rgb, std_rgb),\n",
    "])\n",
    "\n",
    "# Since we are using CIFAR100, the images are all of size 32x32. Therefore no center crop is done.\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_rgb, std_rgb),\n",
    "])\n",
    "print(\"Preprocessing Step Successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization of train_data and val_data successful.\n"
     ]
    }
   ],
   "source": [
    "# Batch Size for Each GPU\n",
    "per_device_batch_size = 128\n",
    "# Number of data loader workers\n",
    "num_workers = 2\n",
    "# Calculate effective total batch size\n",
    "batch_size = per_device_batch_size * num_gpus\n",
    "\n",
    "# Set train=True for training data\n",
    "# Set shuffle=True to shuffle the training data\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR100(train=True).transform_first(transform_train),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    last_batch='discard', \n",
    "    num_workers=num_workers)\n",
    "\n",
    "# Set train=False for validation data\n",
    "# Set shuffle=False to shuffle the testing data\n",
    "val_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR100(train=False).transform_first(transform_test),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers)\n",
    "print(\"Initialization of train_data and val_data successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate decay factor\n",
    "lr_decay = 0.1\n",
    "# Epochs where learning rate decays\n",
    "lr_decay_epoch = [30, 60, 90, np.inf]\n",
    "\n",
    "# Adam optimizer using default parameters recommended in MachineLearningMastery.com\n",
    "optimizer = 'adam'\n",
    "optimizer_params = {'learning_rate': 0.001,\n",
    "                    'beta1': 0.9,\n",
    "                    'beta2': 0.999,\n",
    "                    'epsilon':10e-8}\n",
    "\n",
    "# Define our trainer for net\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)\n",
    "\n",
    "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "train_metric = mx.metric.Accuracy()\n",
    "train_history = TrainingHistory(['training-error', 'validation-error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ctx, val_data):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop started:\n",
      "[Epoch 0] train=0.170913 val=0.241300 loss=136735.996033 time: 31.765953\n",
      "[Epoch 1] train=0.292909 val=0.340000 loss=113135.162064 time: 31.608158\n",
      "[Epoch 2] train=0.367668 val=0.374700 loss=100769.268036 time: 31.675509\n",
      "[Epoch 3] train=0.417087 val=0.412300 loss=92240.715729 time: 31.551225\n",
      "[Epoch 4] train=0.461078 val=0.482500 loss=84959.690170 time: 31.489980\n",
      "[Epoch 5] train=0.496835 val=0.500400 loss=79570.799179 time: 31.517719\n",
      "[Epoch 6] train=0.522656 val=0.469000 loss=74753.475220 time: 31.548121\n",
      "[Epoch 7] train=0.548718 val=0.537700 loss=70674.872345 time: 31.554014\n",
      "[Epoch 8] train=0.569391 val=0.567600 loss=67587.618179 time: 31.591007\n",
      "[Epoch 9] train=0.589123 val=0.568000 loss=64431.363937 time: 31.771161\n",
      "[Epoch 10] train=0.600621 val=0.596100 loss=62049.830833 time: 31.379682\n",
      "[Epoch 11] train=0.615545 val=0.595000 loss=59789.576927 time: 31.650404\n",
      "[Epoch 12] train=0.627384 val=0.623900 loss=57885.659454 time: 31.668793\n",
      "[Epoch 13] train=0.640465 val=0.607900 loss=55901.475273 time: 31.752889\n",
      "[Epoch 14] train=0.653946 val=0.625900 loss=53646.962509 time: 31.657917\n",
      "[Epoch 15] train=0.662861 val=0.611500 loss=52411.163788 time: 31.337009\n",
      "[Epoch 16] train=0.675321 val=0.629600 loss=50541.747398 time: 31.701785\n",
      "[Epoch 17] train=0.680529 val=0.649800 loss=49328.072433 time: 31.700909\n",
      "[Epoch 18] train=0.691847 val=0.638600 loss=47749.170944 time: 31.570161\n",
      "[Epoch 19] train=0.698257 val=0.652100 loss=46708.749641 time: 31.730016\n",
      "[Epoch 20] train=0.702744 val=0.660100 loss=45886.017136 time: 31.801653\n",
      "[Epoch 21] train=0.709255 val=0.668600 loss=44765.532753 time: 31.490227\n",
      "[Epoch 22] train=0.718069 val=0.665100 loss=43016.523422 time: 31.561151\n",
      "[Epoch 23] train=0.723938 val=0.674900 loss=42635.949295 time: 31.616071\n",
      "[Epoch 24] train=0.731991 val=0.651000 loss=41255.822975 time: 31.943172\n",
      "[Epoch 25] train=0.737881 val=0.677400 loss=40065.127548 time: 31.930112\n",
      "[Epoch 26] train=0.740966 val=0.679100 loss=39652.919388 time: 31.677630\n",
      "[Epoch 27] train=0.747276 val=0.680800 loss=38727.814865 time: 31.837904\n",
      "[Epoch 28] train=0.751583 val=0.690100 loss=37821.425819 time: 31.429632\n",
      "[Epoch 29] train=0.757412 val=0.697500 loss=37167.997524 time: 31.447080\n",
      "[Epoch 30] train=0.800561 val=0.735000 loss=30776.874813 time: 31.767174\n",
      "[Epoch 31] train=0.817127 val=0.736800 loss=28296.560593 time: 31.871615\n",
      "[Epoch 32] train=0.821835 val=0.735500 loss=27467.754627 time: 31.706132\n",
      "[Epoch 33] train=0.823097 val=0.737200 loss=27002.697544 time: 31.621339\n",
      "[Epoch 34] train=0.827744 val=0.734700 loss=26475.891609 time: 31.907020\n",
      "[Epoch 35] train=0.826823 val=0.737200 loss=26147.264694 time: 31.849056\n",
      "[Epoch 36] train=0.834315 val=0.736700 loss=25433.757601 time: 31.726273\n",
      "[Epoch 37] train=0.834375 val=0.735900 loss=25180.468216 time: 31.886689\n",
      "[Epoch 38] train=0.836999 val=0.737000 loss=24975.154102 time: 31.585312\n",
      "[Epoch 39] train=0.837620 val=0.737500 loss=24823.109550 time: 31.432532\n",
      "[Epoch 40] train=0.839243 val=0.737600 loss=24417.995052 time: 31.551702\n",
      "[Epoch 41] train=0.842348 val=0.736700 loss=24173.826828 time: 31.688806\n",
      "[Epoch 42] train=0.840986 val=0.738700 loss=23972.190739 time: 31.688366\n",
      "[Epoch 43] train=0.845012 val=0.738100 loss=23766.562458 time: 31.761020\n",
      "[Epoch 44] train=0.846474 val=0.736900 loss=23366.667858 time: 31.601046\n",
      "[Epoch 45] train=0.848077 val=0.736200 loss=23106.569431 time: 31.695226\n",
      "[Epoch 46] train=0.848858 val=0.736100 loss=22997.779560 time: 31.600126\n",
      "[Epoch 47] train=0.851562 val=0.736600 loss=22654.616581 time: 31.628112\n",
      "[Epoch 48] train=0.849639 val=0.737800 loss=22535.145805 time: 31.495694\n",
      "[Epoch 49] train=0.852364 val=0.735800 loss=22418.666428 time: 31.648129\n",
      "[Epoch 50] train=0.851723 val=0.737100 loss=22284.038624 time: 32.076376\n",
      "[Epoch 51] train=0.856190 val=0.736100 loss=21878.924761 time: 31.354550\n",
      "[Epoch 52] train=0.855168 val=0.737000 loss=21858.934624 time: 31.879879\n",
      "[Epoch 53] train=0.858614 val=0.735900 loss=21511.633602 time: 31.757873\n",
      "[Epoch 54] train=0.858313 val=0.736900 loss=21338.682276 time: 31.908460\n",
      "[Epoch 55] train=0.858413 val=0.735800 loss=21188.638502 time: 31.757053\n",
      "[Epoch 56] train=0.859916 val=0.733500 loss=21018.492918 time: 31.480817\n",
      "[Epoch 57] train=0.863081 val=0.738000 loss=20722.454895 time: 31.417294\n",
      "[Epoch 58] train=0.863462 val=0.733200 loss=20702.384537 time: 31.524054\n",
      "[Epoch 59] train=0.863802 val=0.737900 loss=20447.826740 time: 31.734300\n",
      "[Epoch 60] train=0.869511 val=0.740600 loss=19814.656258 time: 31.596582\n",
      "[Epoch 61] train=0.870192 val=0.738100 loss=19563.730255 time: 31.564009\n",
      "[Epoch 62] train=0.871755 val=0.738600 loss=19399.054873 time: 31.923371\n",
      "[Epoch 63] train=0.873377 val=0.738400 loss=19234.919283 time: 32.003728\n",
      "[Epoch 64] train=0.871815 val=0.739400 loss=19459.278357 time: 31.669104\n",
      "[Epoch 65] train=0.872536 val=0.738400 loss=19185.834620 time: 31.756829\n",
      "[Epoch 66] train=0.871875 val=0.739300 loss=19296.172499 time: 31.625753\n",
      "[Epoch 67] train=0.873718 val=0.738900 loss=19046.675760 time: 31.467083\n",
      "[Epoch 68] train=0.871234 val=0.737700 loss=19426.066933 time: 31.673168\n",
      "[Epoch 69] train=0.872095 val=0.736600 loss=19385.774488 time: 31.507043\n",
      "[Epoch 70] train=0.873297 val=0.737700 loss=19079.136580 time: 31.563260\n",
      "[Epoch 71] train=0.874519 val=0.739000 loss=19161.306257 time: 31.672667\n",
      "[Epoch 72] train=0.877143 val=0.738100 loss=18813.038523 time: 31.618917\n",
      "[Epoch 73] train=0.873417 val=0.739400 loss=19078.157293 time: 31.621611\n",
      "[Epoch 74] train=0.874940 val=0.736700 loss=18957.468159 time: 31.518818\n",
      "[Epoch 75] train=0.873938 val=0.739900 loss=18999.802719 time: 31.862891\n",
      "[Epoch 76] train=0.874419 val=0.740400 loss=18880.199347 time: 31.504055\n",
      "[Epoch 77] train=0.875080 val=0.738500 loss=18915.265192 time: 31.495009\n",
      "[Epoch 78] train=0.876122 val=0.738700 loss=18994.165464 time: 31.638528\n",
      "[Epoch 79] train=0.874119 val=0.738200 loss=18885.965271 time: 31.445279\n",
      "[Epoch 80] train=0.877945 val=0.738400 loss=18551.992601 time: 31.567090\n",
      "[Epoch 81] train=0.875481 val=0.738000 loss=18881.115671 time: 31.541926\n",
      "[Epoch 82] train=0.876142 val=0.738100 loss=18847.237780 time: 31.834070\n",
      "[Epoch 83] train=0.875921 val=0.738900 loss=18919.525148 time: 31.557570\n",
      "[Epoch 84] train=0.876542 val=0.737500 loss=18734.841696 time: 31.397313\n",
      "[Epoch 85] train=0.878225 val=0.738100 loss=18486.671768 time: 31.849435\n",
      "[Epoch 86] train=0.875020 val=0.737300 loss=18871.444916 time: 31.575547\n",
      "[Epoch 87] train=0.876322 val=0.737200 loss=18729.937138 time: 31.694638\n",
      "[Epoch 88] train=0.877183 val=0.738000 loss=18554.774372 time: 31.471678\n",
      "[Epoch 89] train=0.877384 val=0.737400 loss=18632.894308 time: 31.729705\n",
      "[Epoch 90] train=0.877985 val=0.737900 loss=18587.094925 time: 31.553677\n",
      "[Epoch 91] train=0.878285 val=0.736200 loss=18424.299227 time: 31.816427\n",
      "[Epoch 92] train=0.878345 val=0.737600 loss=18639.367952 time: 31.646627\n",
      "[Epoch 93] train=0.876943 val=0.738000 loss=18672.011103 time: 31.711551\n",
      "[Epoch 94] train=0.876623 val=0.738200 loss=18631.575773 time: 31.516778\n",
      "[Epoch 95] train=0.876322 val=0.737900 loss=18625.726273 time: 31.576181\n",
      "[Epoch 96] train=0.876202 val=0.736300 loss=18587.929161 time: 31.761711\n",
      "[Epoch 97] train=0.877925 val=0.736200 loss=18494.420650 time: 31.706036\n",
      "[Epoch 98] train=0.878045 val=0.736700 loss=18486.309521 time: 31.674222\n",
      "[Epoch 99] train=0.877083 val=0.738100 loss=18618.512703 time: 31.710776\n",
      "[Epoch 100] train=0.877564 val=0.735600 loss=18351.582693 time: 31.631181\n",
      "[Epoch 101] train=0.877404 val=0.737000 loss=18546.732119 time: 31.709255\n",
      "[Epoch 102] train=0.877143 val=0.738600 loss=18502.729111 time: 31.630208\n",
      "[Epoch 103] train=0.880168 val=0.737700 loss=18373.305035 time: 31.563926\n",
      "[Epoch 104] train=0.877344 val=0.738600 loss=18403.275885 time: 31.587279\n",
      "[Epoch 105] train=0.876903 val=0.737900 loss=18587.353401 time: 31.434571\n",
      "[Epoch 106] train=0.876703 val=0.736800 loss=18542.899910 time: 31.758254\n",
      "[Epoch 107] train=0.878185 val=0.739200 loss=18382.183634 time: 31.564005\n",
      "[Epoch 108] train=0.875461 val=0.738000 loss=18610.690506 time: 31.682425\n",
      "[Epoch 109] train=0.876663 val=0.738500 loss=18533.031406 time: 31.854260\n",
      "[Epoch 110] train=0.877544 val=0.737300 loss=18516.484549 time: 31.752642\n",
      "[Epoch 111] train=0.877925 val=0.738400 loss=18387.568237 time: 31.543516\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 112] train=0.877644 val=0.736600 loss=18536.547167 time: 31.591755\n",
      "[Epoch 113] train=0.876683 val=0.736700 loss=18562.099024 time: 31.671053\n",
      "[Epoch 114] train=0.878385 val=0.737200 loss=18463.170204 time: 31.938352\n",
      "[Epoch 115] train=0.878646 val=0.737100 loss=18478.394690 time: 31.368691\n",
      "[Epoch 116] train=0.876703 val=0.738100 loss=18697.911213 time: 31.661418\n",
      "[Epoch 117] train=0.879527 val=0.738100 loss=18353.435616 time: 31.572303\n",
      "[Epoch 118] train=0.877504 val=0.736600 loss=18605.109114 time: 31.667896\n",
      "[Epoch 119] train=0.879026 val=0.737600 loss=18252.468145 time: 31.737233\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 120\n",
    "lr_decay_count = 0\n",
    "\n",
    "print(\"Training loop started:\")\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    train_metric.reset()\n",
    "    train_loss = 0\n",
    "\n",
    "    # Learning rate decay\n",
    "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
    "        lr_decay_count += 1\n",
    "\n",
    "    # Loop through each batch of training data\n",
    "    for i, batch in enumerate(train_data):\n",
    "        # Extract data and label\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "\n",
    "        # AutoGrad\n",
    "        with ag.record():\n",
    "            output = [net(X) for X in data]\n",
    "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
    "\n",
    "        # Backpropagation\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "\n",
    "        # Optimize\n",
    "        trainer.step(batch_size)\n",
    "\n",
    "        # Update metrics\n",
    "        train_loss += sum([l.sum().asscalar() for l in loss])\n",
    "        train_metric.update(label, output)\n",
    "\n",
    "    name, acc = train_metric.get()\n",
    "    # Evaluate on Validation data\n",
    "    name, val_acc = test(ctx, val_data)\n",
    "\n",
    "    # Update history and print metrics\n",
    "    train_history.update([1-acc, 1-val_acc])\n",
    "    print('[Epoch %d] train=%f val=%f loss=%f time: %f' %\n",
    "        (epoch, acc, val_acc, train_loss, time.time()-tic))\n",
    "\n",
    "# We can plot the metric scores with:\n",
    "train_history.plot(['training-error', 'validation-error'], save_path=\"./cifar100_resnet56_v1_adam.png\")\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
