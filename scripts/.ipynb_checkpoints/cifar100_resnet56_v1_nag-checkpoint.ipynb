{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports successful\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import argparse, time, logging, random, math\n",
    "\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "\n",
    "from mxnet import gluon, nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.gluon.data.vision import transforms\n",
    "\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.utils import makedirs, TrainingHistory\n",
    "from gluoncv.data import transforms as gcv_transforms\n",
    "print(\"Imports successful\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Init Done.\n"
     ]
    }
   ],
   "source": [
    "# number of GPUs to use\n",
    "num_gpus = 1\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "\n",
    "net = get_model('cifar_resnet56_v1', classes=100)\n",
    "net.initialize(mx.init.Xavier(), ctx = ctx)\n",
    "print(\"Model Init Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing Step Successful.\n"
     ]
    }
   ],
   "source": [
    "resize = 32\n",
    "mean_rgb = [0.485, 0.456, 0.406]\n",
    "std_rgb = [0.229, 0.224, 0.225]\n",
    "max_aspect_ratio = 4.0 / 3.0\n",
    "min_aspect_ratio = 3.0 / 4.0\n",
    "max_random_area = 1\n",
    "min_random_area = 0.08\n",
    "jitter_param = 0.4\n",
    "lighting_param = 0.1\n",
    "\n",
    "transform_train = transforms.Compose([    \n",
    "#     transforms.RandomResizedCrop(resize,\n",
    "#                                  scale=(min_random_area, max_random_area), \n",
    "#                                  ratio=(min_aspect_ratio, max_aspect_ratio)),\n",
    "    \n",
    "        # Randomly flip the image horizontally\n",
    "    transforms.RandomFlipLeftRight(),\n",
    "    \n",
    "    transforms.RandomBrightness(brightness=jitter_param),\n",
    "    transforms.RandomSaturation(saturation=jitter_param),\n",
    "    transforms.RandomHue(hue=jitter_param),\n",
    "    \n",
    "    transforms.RandomLighting(lighting_param),\n",
    "    \n",
    "    # Randomly crop an area and resize it to be 32x32, then pad it to be 40x40\n",
    "    gcv_transforms.RandomCrop(32, pad=4),\n",
    "        \n",
    "    # Transpose the image from height*width*num_channels to num_channels*height*width\n",
    "    # and map values from [0, 255] to [0,1]\n",
    "    transforms.ToTensor(),\n",
    "    \n",
    "    # Normalize the image with mean and standard deviation calculated across all images\n",
    "    transforms.Normalize(mean_rgb, std_rgb),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean_rgb, std_rgb),\n",
    "])\n",
    "print(\"Preprocessing Step Successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initialization of train_data and val_data successful.\n"
     ]
    }
   ],
   "source": [
    "# Batch Size for Each GPU\n",
    "per_device_batch_size = 128\n",
    "\n",
    "# Number of data loader workers\n",
    "num_workers = 2\n",
    "\n",
    "# Calculate effective total batch size\n",
    "batch_size = per_device_batch_size * num_gpus\n",
    "\n",
    "# Set train=True for training data\n",
    "# Set shuffle=True to shuffle the training data\n",
    "train_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR100(train=True).transform_first(transform_train),\n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    last_batch='discard', \n",
    "    num_workers=num_workers)\n",
    "\n",
    "# Set train=False for validation data\n",
    "# Set shuffle=False to shuffle the testing data\n",
    "val_data = gluon.data.DataLoader(\n",
    "    gluon.data.vision.CIFAR100(train=False).transform_first(transform_test),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    num_workers=num_workers)\n",
    "print(\"Initialization of train_data and val_data successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning rate decay factor\n",
    "lr_decay = 0.1\n",
    "# Epochs where learning rate decays\n",
    "lr_decay_epoch = [30, 60, 90, np.inf]\n",
    "\n",
    "# Nesterov accelerated gradient descent and set parameters (based of off \n",
    "# reference papers and default values):\n",
    "optimizer = 'nag'\n",
    "optimizer_params = {'learning_rate': 0.1, 'wd': 0.0001, 'momentum': 0.9}\n",
    "\n",
    "# Define our trainer for net\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)\n",
    "\n",
    "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()\n",
    "\n",
    "train_metric = mx.metric.Accuracy()\n",
    "train_history = TrainingHistory(['training-error', 'validation-error'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ctx, val_data):\n",
    "    metric = mx.metric.Accuracy()\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "        outputs = [net(X) for X in data]\n",
    "        metric.update(label, outputs)\n",
    "    return metric.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loop started:\n",
      "[Epoch 0] train=0.112440 val=0.184800 loss=144905.860718 time: 31.373609\n",
      "[Epoch 1] train=0.208213 val=0.258600 loss=128627.814301 time: 31.664320\n",
      "[Epoch 2] train=0.280869 val=0.318200 loss=115717.348953 time: 31.714488\n",
      "[Epoch 3] train=0.350461 val=0.376700 loss=104245.245316 time: 31.550837\n",
      "[Epoch 4] train=0.400942 val=0.433500 loss=95579.661545 time: 31.395588\n",
      "[Epoch 5] train=0.442728 val=0.441100 loss=88553.927383 time: 31.412148\n",
      "[Epoch 6] train=0.476783 val=0.471800 loss=82882.222076 time: 31.547659\n",
      "[Epoch 7] train=0.506991 val=0.483500 loss=78237.916214 time: 31.614549\n",
      "[Epoch 8] train=0.528746 val=0.525100 loss=74022.455048 time: 31.267156\n",
      "[Epoch 9] train=0.550541 val=0.547900 loss=70654.786041 time: 31.464284\n",
      "[Epoch 10] train=0.574519 val=0.572900 loss=67095.312439 time: 31.335085\n",
      "[Epoch 11] train=0.591647 val=0.563400 loss=64061.742859 time: 31.553870\n",
      "[Epoch 12] train=0.605228 val=0.578600 loss=61607.814041 time: 31.851972\n",
      "[Epoch 13] train=0.624780 val=0.609500 loss=58926.672241 time: 31.479921\n",
      "[Epoch 14] train=0.636078 val=0.606900 loss=57015.316170 time: 31.447090\n",
      "[Epoch 15] train=0.644231 val=0.617300 loss=55365.746658 time: 31.459979\n",
      "[Epoch 16] train=0.655128 val=0.617100 loss=53449.771065 time: 31.602636\n",
      "[Epoch 17] train=0.666246 val=0.627300 loss=52212.284691 time: 31.327748\n",
      "[Epoch 18] train=0.671214 val=0.650300 loss=50991.915321 time: 31.466665\n",
      "[Epoch 19] train=0.679187 val=0.647900 loss=49803.623947 time: 31.607986\n",
      "[Epoch 20] train=0.691066 val=0.641000 loss=48236.284691 time: 31.610529\n",
      "[Epoch 21] train=0.694872 val=0.667600 loss=47681.382797 time: 31.509346\n",
      "[Epoch 22] train=0.699720 val=0.670000 loss=46710.660385 time: 31.587614\n",
      "[Epoch 23] train=0.705669 val=0.642100 loss=45615.989357 time: 31.722349\n",
      "[Epoch 24] train=0.708754 val=0.648700 loss=45124.303040 time: 31.337246\n",
      "[Epoch 25] train=0.713742 val=0.650300 loss=44535.233063 time: 31.424080\n",
      "[Epoch 26] train=0.721214 val=0.657900 loss=43128.559776 time: 31.537750\n",
      "[Epoch 27] train=0.721194 val=0.628000 loss=43202.981430 time: 31.530851\n",
      "[Epoch 28] train=0.725321 val=0.632200 loss=42336.664497 time: 31.676927\n",
      "[Epoch 29] train=0.729748 val=0.655600 loss=41868.557907 time: 31.216536\n",
      "[Epoch 30] train=0.783894 val=0.735300 loss=33438.887905 time: 31.619555\n",
      "[Epoch 31] train=0.814203 val=0.738800 loss=28794.838833 time: 31.515544\n",
      "[Epoch 32] train=0.823097 val=0.745900 loss=27524.629280 time: 31.704986\n",
      "[Epoch 33] train=0.827945 val=0.748300 loss=26577.066280 time: 31.340467\n",
      "[Epoch 34] train=0.833774 val=0.747200 loss=25503.164223 time: 31.545331\n",
      "[Epoch 35] train=0.835397 val=0.744000 loss=25035.846268 time: 31.560086\n",
      "[Epoch 36] train=0.839563 val=0.750600 loss=24301.360668 time: 31.370207\n",
      "[Epoch 37] train=0.842829 val=0.749800 loss=23964.248177 time: 31.567428\n",
      "[Epoch 38] train=0.847075 val=0.749000 loss=23064.811293 time: 31.376757\n",
      "[Epoch 39] train=0.850761 val=0.749600 loss=22694.750191 time: 31.321891\n",
      "[Epoch 40] train=0.852524 val=0.747900 loss=22345.675205 time: 31.651131\n",
      "[Epoch 41] train=0.857532 val=0.745700 loss=21837.396784 time: 31.710616\n",
      "[Epoch 42] train=0.858534 val=0.745400 loss=21455.954109 time: 31.472551\n",
      "[Epoch 43] train=0.860156 val=0.746500 loss=21211.726912 time: 31.455898\n",
      "[Epoch 44] train=0.864724 val=0.745000 loss=20647.056475 time: 31.611220\n",
      "[Epoch 45] train=0.865865 val=0.745700 loss=20215.133698 time: 31.246896\n",
      "[Epoch 46] train=0.868610 val=0.751400 loss=20043.836124 time: 31.552764\n",
      "[Epoch 47] train=0.870613 val=0.743900 loss=19636.837618 time: 31.483744\n",
      "[Epoch 48] train=0.872296 val=0.744700 loss=19478.073120 time: 31.444600\n",
      "[Epoch 49] train=0.872977 val=0.751900 loss=19015.871445 time: 31.717179\n",
      "[Epoch 50] train=0.877684 val=0.746200 loss=18507.042656 time: 31.787334\n",
      "[Epoch 51] train=0.878766 val=0.746200 loss=18325.005625 time: 31.469217\n",
      "[Epoch 52] train=0.881190 val=0.745700 loss=17954.954149 time: 31.777575\n",
      "[Epoch 53] train=0.882592 val=0.743200 loss=17811.116926 time: 31.489027\n",
      "[Epoch 54] train=0.881731 val=0.746100 loss=17621.255352 time: 31.424637\n",
      "[Epoch 55] train=0.888582 val=0.741000 loss=17017.015047 time: 31.585206\n",
      "[Epoch 56] train=0.887800 val=0.743100 loss=16756.260031 time: 31.651851\n",
      "[Epoch 57] train=0.891206 val=0.745200 loss=16338.753855 time: 31.404682\n",
      "[Epoch 58] train=0.891747 val=0.740200 loss=16275.442545 time: 31.706458\n",
      "[Epoch 59] train=0.889343 val=0.747100 loss=16440.841835 time: 31.520308\n",
      "[Epoch 60] train=0.904748 val=0.750900 loss=14521.363706 time: 31.516033\n",
      "[Epoch 61] train=0.911739 val=0.753800 loss=13374.731041 time: 31.584619\n",
      "[Epoch 62] train=0.913882 val=0.751600 loss=13180.145235 time: 31.666547\n",
      "[Epoch 63] train=0.916446 val=0.753700 loss=12885.854870 time: 31.618828\n",
      "[Epoch 64] train=0.916006 val=0.753600 loss=12970.717155 time: 31.599272\n",
      "[Epoch 65] train=0.916707 val=0.756200 loss=12759.444118 time: 31.299263\n",
      "[Epoch 66] train=0.917949 val=0.753400 loss=12654.070211 time: 31.485694\n",
      "[Epoch 67] train=0.919251 val=0.753800 loss=12423.777012 time: 31.474447\n",
      "[Epoch 68] train=0.917829 val=0.754800 loss=12435.010200 time: 31.513577\n",
      "[Epoch 69] train=0.918950 val=0.754500 loss=12397.780948 time: 31.282820\n",
      "[Epoch 70] train=0.921955 val=0.755500 loss=12027.972327 time: 31.642056\n",
      "[Epoch 71] train=0.922476 val=0.755300 loss=12039.042500 time: 31.507939\n",
      "[Epoch 72] train=0.922336 val=0.755300 loss=12003.011710 time: 31.316438\n",
      "[Epoch 73] train=0.921174 val=0.753900 loss=11948.933591 time: 31.426458\n",
      "[Epoch 74] train=0.920913 val=0.754600 loss=11990.021051 time: 31.641260\n",
      "[Epoch 75] train=0.922776 val=0.753500 loss=11982.997508 time: 31.627954\n",
      "[Epoch 76] train=0.925280 val=0.753900 loss=11529.433253 time: 31.368946\n",
      "[Epoch 77] train=0.924519 val=0.754100 loss=11706.642626 time: 31.507053\n",
      "[Epoch 78] train=0.922917 val=0.753300 loss=11575.024416 time: 31.702184\n",
      "[Epoch 79] train=0.924960 val=0.753700 loss=11484.292286 time: 31.324345\n",
      "[Epoch 80] train=0.924219 val=0.753000 loss=11579.082808 time: 31.470615\n",
      "[Epoch 81] train=0.925661 val=0.755000 loss=11343.319801 time: 31.667664\n",
      "[Epoch 82] train=0.926002 val=0.753900 loss=11362.757775 time: 31.438195\n",
      "[Epoch 83] train=0.926242 val=0.755100 loss=11212.771029 time: 31.429156\n",
      "[Epoch 84] train=0.926583 val=0.755300 loss=11204.071959 time: 31.659471\n",
      "[Epoch 85] train=0.927464 val=0.755600 loss=11118.298050 time: 31.303200\n",
      "[Epoch 86] train=0.926923 val=0.753400 loss=11030.324549 time: 31.180243\n",
      "[Epoch 87] train=0.926963 val=0.755400 loss=11260.970497 time: 31.748849\n",
      "[Epoch 88] train=0.928586 val=0.755900 loss=11017.077306 time: 31.576148\n",
      "[Epoch 89] train=0.928285 val=0.752300 loss=10838.126934 time: 31.613752\n",
      "[Epoch 90] train=0.931410 val=0.752500 loss=10625.235503 time: 31.797819\n",
      "[Epoch 91] train=0.929026 val=0.753700 loss=10761.116918 time: 31.434287\n",
      "[Epoch 92] train=0.930950 val=0.753100 loss=10723.438081 time: 31.356726\n",
      "[Epoch 93] train=0.929808 val=0.753400 loss=10630.259866 time: 31.404656\n",
      "[Epoch 94] train=0.930228 val=0.752500 loss=10636.594362 time: 31.292035\n",
      "[Epoch 95] train=0.932712 val=0.753500 loss=10507.835947 time: 31.471308\n",
      "[Epoch 96] train=0.930228 val=0.753800 loss=10564.736583 time: 31.529340\n",
      "[Epoch 97] train=0.931050 val=0.753600 loss=10570.075249 time: 31.750390\n",
      "[Epoch 98] train=0.933193 val=0.752800 loss=10344.026395 time: 31.310905\n",
      "[Epoch 99] train=0.930188 val=0.753100 loss=10722.535683 time: 31.781339\n",
      "[Epoch 100] train=0.930689 val=0.753000 loss=10648.007845 time: 31.500403\n",
      "[Epoch 101] train=0.932452 val=0.751900 loss=10437.315172 time: 31.328415\n",
      "[Epoch 102] train=0.933734 val=0.754000 loss=10437.624717 time: 31.508307\n",
      "[Epoch 103] train=0.930048 val=0.753900 loss=10618.919824 time: 31.481020\n",
      "[Epoch 104] train=0.932171 val=0.752400 loss=10511.596527 time: 31.524256\n",
      "[Epoch 105] train=0.931931 val=0.752800 loss=10536.195537 time: 31.703646\n",
      "[Epoch 106] train=0.931771 val=0.753400 loss=10569.054875 time: 31.694997\n",
      "[Epoch 107] train=0.933293 val=0.754700 loss=10320.529015 time: 31.601099\n",
      "[Epoch 108] train=0.931671 val=0.755100 loss=10518.038362 time: 31.619415\n",
      "[Epoch 109] train=0.930569 val=0.754800 loss=10475.175342 time: 31.441990\n",
      "[Epoch 110] train=0.932833 val=0.755000 loss=10351.609127 time: 31.689732\n",
      "[Epoch 111] train=0.931591 val=0.754100 loss=10557.514401 time: 31.344888\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 112] train=0.931731 val=0.755200 loss=10560.061697 time: 31.476948\n",
      "[Epoch 113] train=0.931110 val=0.752700 loss=10418.077089 time: 31.524803\n",
      "[Epoch 114] train=0.931490 val=0.753700 loss=10531.947902 time: 31.404940\n",
      "[Epoch 115] train=0.932252 val=0.753300 loss=10458.212238 time: 31.520979\n",
      "[Epoch 116] train=0.931671 val=0.752700 loss=10349.889950 time: 31.331285\n",
      "[Epoch 117] train=0.932232 val=0.752800 loss=10484.494047 time: 31.411422\n",
      "[Epoch 118] train=0.931851 val=0.753400 loss=10469.679489 time: 31.767691\n",
      "[Epoch 119] train=0.932692 val=0.752600 loss=10323.764117 time: 31.412828\n",
      "Done.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = 120\n",
    "lr_decay_count = 0\n",
    "\n",
    "print(\"Training loop started:\")\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    train_metric.reset()\n",
    "    train_loss = 0\n",
    "\n",
    "    # Learning rate decay\n",
    "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
    "        lr_decay_count += 1\n",
    "\n",
    "    # Loop through each batch of training data\n",
    "    for i, batch in enumerate(train_data):\n",
    "        # Extract data and label\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "\n",
    "        # AutoGrad\n",
    "        with ag.record():\n",
    "            output = [net(X) for X in data]\n",
    "            loss = [loss_fn(yhat, y) for yhat, y in zip(output, label)]\n",
    "\n",
    "        # Backpropagation\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "\n",
    "        # Optimize\n",
    "        trainer.step(batch_size)\n",
    "\n",
    "        # Update metrics\n",
    "        train_loss += sum([l.sum().asscalar() for l in loss])\n",
    "        train_metric.update(label, output)\n",
    "\n",
    "    name, acc = train_metric.get()\n",
    "    # Evaluate on Validation data\n",
    "    name, val_acc = test(ctx, val_data)\n",
    "\n",
    "    # Update history and print metrics\n",
    "    train_history.update([1-acc, 1-val_acc])\n",
    "    print('[Epoch %d] train=%f val=%f loss=%f time: %f' %\n",
    "        (epoch, acc, val_acc, train_loss, time.time()-tic))\n",
    "\n",
    "# We can plot the metric scores with:\n",
    "train_history.plot(['training-error', 'validation-error'], save_path=\"./cifar100_resnet56_v1_nag.png\")\n",
    "print(\"Done.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
