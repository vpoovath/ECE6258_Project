{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imports Successful!\n"
     ]
    }
   ],
   "source": [
    "import argparse, time\n",
    "import numpy as np\n",
    "import os\n",
    "import mxnet as mx\n",
    "\n",
    "from mxnet import gluon, nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.io import ImageRecordIter\n",
    "\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.utils import makedirs, TrainingHistory\n",
    "mx.random.seed(1)\n",
    "print(\"Imports Successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Init Complete.\n"
     ]
    }
   ],
   "source": [
    "num_gpus = 1\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "\n",
    "# Get the model ResNet50_v2 with 10 output classes\n",
    "net = get_model('ResNet50_v2', classes=1000)\n",
    "#net.initialize(mx.init.MSRAPrelu(), ctx=ctx)\n",
    "net.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "print(\"Net Init Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RecordIter Setup Done.\n"
     ]
    }
   ],
   "source": [
    "jitter_param = 0.4\n",
    "lighting_param = 0.1\n",
    "mean_rgb = [123.68, 116.779, 103.939]\n",
    "std_rgb = [58.393, 57.12, 57.375]\n",
    "\n",
    "train_data = mx.io.ImageRecordIter(\n",
    "    path_imgrec = '/newvolume/ImageNet-ILSVRC2012/training/train_rec.rec',\n",
    "    path_imgidx = '/newvolume/ImageNet-ILSVRC2012/training/train_rec.idx',\n",
    "    preprocess_threads  = 32,\n",
    "    shuffle             = True,\n",
    "    batch_size          = 64,\n",
    "\n",
    "    data_shape          = (3, 224, 224),\n",
    "    mean_r              = mean_rgb[0],\n",
    "    mean_g              = mean_rgb[1],\n",
    "    mean_b              = mean_rgb[2],\n",
    "    std_r               = std_rgb[0],\n",
    "    std_g               = std_rgb[1],\n",
    "    std_b               = std_rgb[2],\n",
    "    rand_mirror         = True,\n",
    "    random_resized_crop = True,\n",
    "    max_aspect_ratio    = 4. / 3.,\n",
    "    min_aspect_ratio    = 3. / 4.,\n",
    "    max_random_area     = 1,\n",
    "    min_random_area     = 0.08,\n",
    "    brightness          = jitter_param,\n",
    "    saturation          = jitter_param,\n",
    "    contrast            = jitter_param,\n",
    "    pca_noise           = lighting_param,\n",
    ")\n",
    "\n",
    "val_data = mx.io.ImageRecordIter(\n",
    "    path_imgrec = '/newvolume/ImageNet-ILSVRC2012/testing/val_rec.rec',\n",
    "    path_imgidx = '/newvolume/ImageNet-ILSVRC2012/testing/val_rec.idx',\n",
    "    preprocess_threads  = 32,\n",
    "    shuffle             = False,\n",
    "    batch_size          = 64,\n",
    "\n",
    "    resize              = 256,\n",
    "    data_shape          = (3, 224, 224),\n",
    "    mean_r              = mean_rgb[0],\n",
    "    mean_g              = mean_rgb[1],\n",
    "    mean_b              = mean_rgb[2],\n",
    "    std_r               = std_rgb[0],\n",
    "    std_g               = std_rgb[1],\n",
    "    std_b               = std_rgb[2],\n",
    ")\n",
    "print(\"RecordIter Setup Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer, Loss, and Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decay = 0.10 # Learning rate should be divided by 10 (1/10).\n",
    "lr_decay_epoch = [30, 60, 90, np.inf]\n",
    "optimizer = 'nag'\n",
    "optimizer_params = {'learning_rate': 0.1, 'wd':0.0001, 'momentum':0.9}\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1000 classes the model may not always rate the correct answer with the highest rank. Besides top-1 accuracy, we want top-5 accuracy for how well the model is doing. At the end of every epoch, we reocrd and print the metric scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_top1 = mx.metric.Accuracy()\n",
    "acc_top5 = mx.metric.TopKAccuracy(5)\n",
    "train_history = TrainingHistory(['training-top1-err', 'training-top5-err',\n",
    "                                 'validation-top1-err', 'validation-top5-err'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ctx, val_data):\n",
    "    acc_top1_val = mx.metric.Accuracy()\n",
    "    acc_top5_val = mx.metric.TopKAccuracy(5)\n",
    "    for i, batch in enumerate(val_data):\n",
    "        data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "        outputs = [net(X) for X in data]\n",
    "        acc_top1_val.update(label, outputs)\n",
    "        acc_top5_val.update(label, outputs)\n",
    "\n",
    "    _, top1 = acc_top1_val.get()\n",
    "    _, top5 = acc_top5_val.get()\n",
    "    return (1 - top1, 1 - top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loop Started:\n",
      "<class 'list'>\n",
      "<class 'list'>\n",
      "Epoch[0] Batch [49]:\tSpeed: 246.614846 samples/sec\ttop1-err=0.999375\ttop5-err=0.995625\ttrain_loss=23491.233490\n",
      "Epoch[0] Batch [99]:\tSpeed: 326.187525 samples/sec\ttop1-err=0.998906\ttop5-err=0.994219\ttrain_loss=45683.377411\n",
      "Epoch[0] Batch [149]:\tSpeed: 326.479399 samples/sec\ttop1-err=0.998958\ttop5-err=0.994062\ttrain_loss=67811.357422\n",
      "Epoch[0] Batch [199]:\tSpeed: 326.403607 samples/sec\ttop1-err=0.998906\ttop5-err=0.993516\ttrain_loss=89902.955475\n",
      "Epoch[0] Batch [249]:\tSpeed: 325.888014 samples/sec\ttop1-err=0.999000\ttop5-err=0.992875\ttrain_loss=111919.273621\n",
      "Epoch[0] Batch [299]:\tSpeed: 326.126678 samples/sec\ttop1-err=0.998958\ttop5-err=0.992188\ttrain_loss=133886.583130\n",
      "Epoch[0] Batch [349]:\tSpeed: 325.936748 samples/sec\ttop1-err=0.998705\ttop5-err=0.991250\ttrain_loss=155829.158844\n",
      "Epoch[0] Batch [399]:\tSpeed: 325.276228 samples/sec\ttop1-err=0.998398\ttop5-err=0.990703\ttrain_loss=177743.274475\n",
      "Epoch[0] Batch [449]:\tSpeed: 325.348618 samples/sec\ttop1-err=0.998333\ttop5-err=0.990347\ttrain_loss=199535.790436\n",
      "Epoch[0] Batch [499]:\tSpeed: 325.406334 samples/sec\ttop1-err=0.998062\ttop5-err=0.989875\ttrain_loss=221308.602692\n",
      "Epoch[0] Batch [549]:\tSpeed: 324.791685 samples/sec\ttop1-err=0.997812\ttop5-err=0.989403\ttrain_loss=243076.617340\n",
      "Epoch[0] Batch [599]:\tSpeed: 326.221980 samples/sec\ttop1-err=0.997682\ttop5-err=0.989062\ttrain_loss=264786.967499\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-d8220b076b5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Update metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0macc_top1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0macc_top5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d8220b076b5a>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Update metrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m         \u001b[0macc_top1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0macc_top5\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_latest_p37/gpu/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masscalar\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2583\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The current array is not a scalar\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2584\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2585\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2586\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2587\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/mxnet_latest_p37/gpu/lib/python3.7/site-packages/mxnet/ndarray/ndarray.py\u001b[0m in \u001b[0;36masnumpy\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2564\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2565\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_void_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2566\u001b[0;31m             ctypes.c_size_t(data.size)))\n\u001b[0m\u001b[1;32m   2567\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2568\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "print(\"Training Loop Started:\")\n",
    "epochs = 120\n",
    "lr_decay_count = 0\n",
    "log_interval = 50\n",
    "batch_size = 64\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    btic = time.time()\n",
    "    acc_top1.reset()\n",
    "    acc_top5.reset()\n",
    "    train_loss = 0\n",
    "\n",
    "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
    "        lr_decay_count += 1\n",
    "\n",
    "    for i, batch in enumerate(train_data):\n",
    "        data = gluon.utils.split_and_load(batch.data[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch.label[0], ctx_list=ctx, batch_axis=0)\n",
    "        \n",
    "        if i == 0:\n",
    "            print(type(data))\n",
    "            print(type(label))\n",
    "        \n",
    "        # Autograd\n",
    "        with ag.record():\n",
    "            outputs = [net(X) for X in data]\n",
    "            loss = [loss_fn(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "        \n",
    "        # Backpropagation\n",
    "        #ag.backward(loss)\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "        \n",
    "        # Optimize\n",
    "        trainer.step(batch_size)\n",
    "        \n",
    "        # Update metrics\n",
    "        train_loss += sum([l.sum().asscalar() for l in loss])\n",
    "        acc_top1.update(label, outputs)\n",
    "        acc_top5.update(label, outputs)\n",
    "        \n",
    "        if log_interval and not (i + 1) % log_interval:\n",
    "            _, top1 = acc_top1.get()\n",
    "            _, top5 = acc_top5.get()\n",
    "            err_top1, err_top5 = (1-top1, 1-top5)\n",
    "            print('Epoch[%d] Batch [%d]:\\tSpeed: %f samples/sec\\ttop1-err=%f\\ttop5-err=%f\\ttrain_loss=%f' %\n",
    "                  (epoch, i, batch_size*log_interval/(time.time()-btic), err_top1, err_top5, train_loss))\n",
    "            btic = time.time()\n",
    "\n",
    "    _, top1 = acc_top1.get()\n",
    "    _, top5 = acc_top5.get()\n",
    "    err_top1, err_top5 = (1-top1, 1-top5)\n",
    "\n",
    "    err_top1_val, err_top5_val = test(ctx, val_data)\n",
    "    train_history.update([err_top1, err_top5, err_top1_val, err_top5_val])\n",
    "\n",
    "    print('[Epoch %d] train_top5=%f train_top1=%f val_top5=%f val_top1=%f loss=%f time: %f' % \n",
    "             (epoch, top5, top1, (1-err_top5_val), (1-err_top1_val), train_loss, time.time()-tic))\n",
    "    #print('[Epoch %d] training: err-top1=%f err-top5=%f'%(epoch, err_top1, err_top5))\n",
    "    #print('[Epoch %d] time cost: %f'%(epoch, time.time()-tic))\n",
    "    #print('[Epoch %d] validation: err-top1=%f err-top5=%f'%(epoch, err_top1_val, err_top5_val))\n",
    "\n",
    "print(\"Training Phase Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_history' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9e38045159e7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# https://cv.gluon.ai/api/utils.html\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'training-top1-err'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'validation-top1-err'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/home/ubuntu/\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Image Plot Saved!\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_history' is not defined"
     ]
    }
   ],
   "source": [
    "# https://cv.gluon.ai/api/utils.html\n",
    "train_history.plot(['training-top1-err', 'validation-top1-err'], save_path=\"/home/ubuntu/\")\n",
    "print(\"Image Plot Saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mxnet_latest_p37] *",
   "language": "python",
   "name": "conda-env-mxnet_latest_p37-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
