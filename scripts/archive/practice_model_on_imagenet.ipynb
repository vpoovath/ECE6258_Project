{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, time\n",
    "import numpy as np\n",
    "import os\n",
    "import mxnet as mx\n",
    "\n",
    "from mxnet import gluon, nd\n",
    "from mxnet import autograd as ag\n",
    "from mxnet.gluon import nn\n",
    "from mxnet.io import ImageRecordIter\n",
    "\n",
    "from gluoncv.model_zoo import get_model\n",
    "from gluoncv.utils import makedirs, TrainingHistory\n",
    "mx.random.seed(1)\n",
    "print(\"Imports Successful!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper Class for DataIter and ImageRecordIter\n",
    "Because ImageRecordIter works with DataIter types and is not well suited for Gluon training loops, create this wrapper class so that a data loader can be used properly with the training loop...\n",
    "We'll see if this works or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataIterLoader():\n",
    "    def __init__(self, data_iter):\n",
    "        self.data_iter = data_iter\n",
    "    \n",
    "    def __iter__(self):\n",
    "        self.data_iter.reset()\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        batch = self.data_iter.__next__()\n",
    "        assert len(batch.data) == len(batch.label) == 1\n",
    "        data = batch.data[0]\n",
    "        label = batch.label[0]\n",
    "        return data, label\n",
    "    \n",
    "    def next(self):\n",
    "        return self.__next__() # For Python 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_gpus = 1\n",
    "ctx = [mx.gpu(i) for i in range(num_gpus)]\n",
    "\n",
    "# Get the model ResNet50_v2 with 10 output classes\n",
    "net = get_model('ResNet50_v2', classes=1000)\n",
    "#net.initialize(mx.init.MSRAPrelu(), ctx=ctx)\n",
    "net.initialize(mx.init.Xavier(), ctx=ctx)\n",
    "print(\"Net Init Complete.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jitter_param = 0.4\n",
    "lighting_param = 0.1\n",
    "mean_rgb = [123.68, 116.779, 103.939]\n",
    "std_rgb = [58.393, 57.12, 57.375]\n",
    "\n",
    "train_data = mx.io.ImageRecordIter(\n",
    "    path_imgrec = '/newvolume/ImageNet-ILSVRC2012/training/train_rec.rec',\n",
    "    path_imgidx = '/newvolume/ImageNet-ILSVRC2012/training/train_rec.idx',\n",
    "    preprocess_threads  = 32,\n",
    "    shuffle             = True,\n",
    "    batch_size          = 64,\n",
    "\n",
    "    data_shape          = (3, 224, 224),\n",
    "    mean_r              = mean_rgb[0],\n",
    "    mean_g              = mean_rgb[1],\n",
    "    mean_b              = mean_rgb[2],\n",
    "    std_r               = std_rgb[0],\n",
    "    std_g               = std_rgb[1],\n",
    "    std_b               = std_rgb[2],\n",
    "    rand_mirror         = True,\n",
    "    random_resized_crop = True,\n",
    "    max_aspect_ratio    = 4. / 3.,\n",
    "    min_aspect_ratio    = 3. / 4.,\n",
    "    max_random_area     = 1,\n",
    "    min_random_area     = 0.08,\n",
    "    brightness          = jitter_param,\n",
    "    saturation          = jitter_param,\n",
    "    contrast            = jitter_param,\n",
    "    pca_noise           = lighting_param,\n",
    ")\n",
    "\n",
    "val_data = mx.io.ImageRecordIter(\n",
    "    path_imgrec = '/newvolume/ImageNet-ILSVRC2012/testing/val_rec.rec',\n",
    "    path_imgidx = '/newvolume/ImageNet-ILSVRC2012/testing/val_rec.idx',\n",
    "    preprocess_threads  = 32,\n",
    "    shuffle             = False,\n",
    "    batch_size          = 64,\n",
    "\n",
    "    resize              = 256,\n",
    "    data_shape          = (3, 224, 224),\n",
    "    mean_r              = mean_rgb[0],\n",
    "    mean_g              = mean_rgb[1],\n",
    "    mean_b              = mean_rgb[2],\n",
    "    std_r               = std_rgb[0],\n",
    "    std_g               = std_rgb[1],\n",
    "    std_b               = std_rgb[2],\n",
    ")\n",
    "print(\"RecordIter Setup Done.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizer, Loss, and Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_decay = 0.10 # Learning rate should be divided by 10 (1/10).\n",
    "lr_decay_epoch = [30, 60, 90, np.inf]\n",
    "optimizer = 'nag'\n",
    "optimizer_params = {'learning_rate': 0.1, 'wd':0.0001, 'momentum':0.9}\n",
    "trainer = gluon.Trainer(net.collect_params(), optimizer, optimizer_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = gluon.loss.SoftmaxCrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 1000 classes the model may not always rate the correct answer with the highest rank. Besides top-1 accuracy, we want top-5 accuracy for how well the model is doing. At the end of every epoch, we reocrd and print the metric scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_top1 = mx.metric.Accuracy()\n",
    "acc_top5 = mx.metric.TopKAccuracy(5)\n",
    "train_history = TrainingHistory(['training-top1-err', 'training-top5-err',\n",
    "                                 'validation-top1-err', 'validation-top5-err'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(ctx, val_data_loader):\n",
    "    acc_top1_val = mx.metric.Accuracy()\n",
    "    acc_top5_val = mx.metric.TopKAccuracy(5)\n",
    "    for i, batch in enumerate(val_data_loader):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "        outputs = [net(X) for X in data]\n",
    "        acc_top1_val.update(label, outputs)\n",
    "        acc_top5_val.update(label, outputs)\n",
    "\n",
    "    _, top1 = acc_top1_val.get()\n",
    "    _, top5 = acc_top5_val.get()\n",
    "    return (1 - top1, 1 - top5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 120\n",
    "lr_decay_count = 0\n",
    "log_interval = 50\n",
    "batch_size = 64\n",
    "\n",
    "print(type(train_data))\n",
    "print(type(val_data))\n",
    "print(\"Creating Data Loaders\")\n",
    "train_data_loader = DataIterLoader(train_data)\n",
    "val_data_loader = DataIterLoader(val_data)\n",
    "print(type(train_data_loader))\n",
    "print(type(val_data_loader))\n",
    "\n",
    "print(\"Training Loop Started:\")\n",
    "for epoch in range(epochs):\n",
    "    tic = time.time()\n",
    "    btic = time.time()\n",
    "    acc_top1.reset()\n",
    "    acc_top5.reset()\n",
    "    train_loss = 0\n",
    "\n",
    "    if epoch == lr_decay_epoch[lr_decay_count]:\n",
    "        trainer.set_learning_rate(trainer.learning_rate*lr_decay)\n",
    "        lr_decay_count += 1\n",
    "\n",
    "    for i, batch in enumerate(train_data_loader):\n",
    "        data = gluon.utils.split_and_load(batch[0], ctx_list=ctx, batch_axis=0)\n",
    "        label = gluon.utils.split_and_load(batch[1], ctx_list=ctx, batch_axis=0)\n",
    "        \n",
    "#         if i == 0:\n",
    "#             print(type(data))\n",
    "#             print(type(label))\n",
    "        \n",
    "        # Autograd\n",
    "        with ag.record():\n",
    "            outputs = [net(X) for X in data]\n",
    "            loss = [loss_fn(yhat, y) for yhat, y in zip(outputs, label)]\n",
    "        \n",
    "        # Backpropagation\n",
    "        #ag.backward(loss)\n",
    "        for l in loss:\n",
    "            l.backward()\n",
    "        \n",
    "        # Optimize\n",
    "        trainer.step(batch_size)\n",
    "        \n",
    "        # Update metrics\n",
    "        train_loss += sum([l.sum().asscalar() for l in loss])\n",
    "        acc_top1.update(label, outputs)\n",
    "        acc_top5.update(label, outputs)\n",
    "        \n",
    "        if log_interval and not (i + 1) % log_interval:\n",
    "            _, top1 = acc_top1.get()\n",
    "            _, top5 = acc_top5.get()\n",
    "            err_top1, err_top5 = (1-top1, 1-top5)\n",
    "            print('Epoch[%d] Batch [%d]:\\tSpeed: %f samples/sec\\ttop1-err=%f\\ttop5-err=%f\\ttrain_loss=%f' %\n",
    "                  (epoch, i, batch_size*log_interval/(time.time()-btic), err_top1, err_top5, train_loss))\n",
    "            btic = time.time()\n",
    "\n",
    "    _, top1 = acc_top1.get()\n",
    "    _, top5 = acc_top5.get()\n",
    "    err_top1, err_top5 = (1-top1, 1-top5)\n",
    "\n",
    "    err_top1_val, err_top5_val = test(ctx, val_data_loader)\n",
    "    train_history.update([err_top1, err_top5, err_top1_val, err_top5_val])\n",
    "\n",
    "    print('[Epoch %d] train_top5=%f train_top1=%f val_top5=%f val_top1=%f loss=%f time: %f' % \n",
    "             (epoch, top5, top1, (1-err_top5_val), (1-err_top1_val), train_loss, time.time()-tic))\n",
    "    #print('[Epoch %d] training: err-top1=%f err-top5=%f'%(epoch, err_top1, err_top5))\n",
    "    #print('[Epoch %d] time cost: %f'%(epoch, time.time()-tic))\n",
    "    #print('[Epoch %d] validation: err-top1=%f err-top5=%f'%(epoch, err_top1_val, err_top5_val))\n",
    "\n",
    "print(\"Training Phase Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cv.gluon.ai/api/utils.html\n",
    "train_history.plot(['training-top1-err', 'validation-top1-err'], save_path=\"/home/ubuntu/\")\n",
    "print(\"Image Plot Saved!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
